{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "1bkiSxymihdBeiswZfJubsNSURQNcBzQZ",
      "authorship_tag": "ABX9TyOhwGPE9oROHO90ctLxoPgp"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj8yZbwW0Klm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000261b1-4cb9-4c03-e24c-eddeaf7dc1c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jumanji\n",
            "  Downloading jumanji-0.3.1.tar.gz (583 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.5/583.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chex>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from jumanji) (0.1.7)\n",
            "Collecting dm-env>=1.5 (from jumanji)\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: gym>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from jumanji) (0.25.2)\n",
            "Requirement already satisfied: jax>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from jumanji) (0.4.14)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from jumanji) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from jumanji) (1.23.5)\n",
            "Requirement already satisfied: Pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from jumanji) (9.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from jumanji) (4.7.1)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.3->jumanji) (1.4.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.3->jumanji) (0.1.8)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.3->jumanji) (0.4.14+cuda11.cudnn86)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.3->jumanji) (0.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.22.0->jumanji) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.22.0->jumanji) (0.0.8)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.26->jumanji) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.26->jumanji) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.26->jumanji) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (4.42.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->jumanji) (1.16.0)\n",
            "Building wheels for collected packages: jumanji\n",
            "  Building wheel for jumanji (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jumanji: filename=jumanji-0.3.1-py3-none-any.whl size=750375 sha256=2d0cb7cf538d3965c9d14623932184ebb78eb6150442d21b14e440ab14b22981\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/29/10/884df072d319d2522cfff8b9c3d61fe60ab3c31e2a054d3e5d\n",
            "Successfully built jumanji\n",
            "Installing collected packages: dm-env, jumanji\n",
            "Successfully installed dm-env-1.6 jumanji-0.3.1\n"
          ]
        }
      ],
      "source": [
        "pip install jumanji"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jumanji\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "import random\n",
        "import os\n",
        "from collections import namedtuple, deque\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "-HAYvDfU0N2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main framework taken from https://github.com/ultronify/dqn-from-scratch-with-tf2/blob/master/\n",
        "\n",
        "class ReplayBuffer:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.memory = deque(maxlen=10000)\n",
        "    self.capacity = 10000\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.memory)\n",
        "\n",
        "  def store(self, state, next_state, reward, action, done):\n",
        "    '''\n",
        "    Records a single step of game play experience\n",
        "    PARAM -\n",
        "    state: current game state\n",
        "    next_state: game state after taking action\n",
        "    reard: reward taking action at the current state brings\n",
        "    action: action taken at the current state\n",
        "    done: boolean to indicate if game is finished after taking action\n",
        "    RETURNS - N/A\n",
        "    '''\n",
        "    if len(self.memory) > self.capacity:\n",
        "      del self.memory[0]\n",
        "    self.memory.append((state, next_state, reward, action, done))\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "    '''\n",
        "    Samples a batch of gameplay experiences for training\n",
        "    PARAM - None\n",
        "    RETURNS - list of gameplay experiences\n",
        "    '''\n",
        "    batch_size = min(128, len(self.memory))\n",
        "    sample_batch = random.sample(self.memory, batch_size)\n",
        "    state_batch = []\n",
        "    next_state_batch = []\n",
        "    reward_batch = []\n",
        "    action_batch = []\n",
        "    done_batch = []\n",
        "    for experience in sample_batch:\n",
        "      state_batch.append(experience[0])\n",
        "      next_state_batch.append(experience[1])\n",
        "      reward_batch.append(experience[2])\n",
        "      action_batch.append(experience[3])\n",
        "      done_batch.append(experience[4])\n",
        "\n",
        "    return  np.array(state_batch), np.array(next_state_batch), np.array(reward_batch), np.array(action_batch), np.array(done_batch)"
      ],
      "metadata": {
        "id": "BGhqoRPx0Qx4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f174dfc8-bd8a-447f-fe63-f843f5b5f347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unravel(state, action_index):\n",
        "  array = np.array(state.action_mask)\n",
        "  rotation, col_index = np.unravel_index(action_index, array.shape)\n",
        "  action = [rotation, col_index]\n",
        "  return action\n",
        "\n",
        "class DqnAgent:\n",
        "  '''\n",
        "  Create DQN agent class\n",
        "  '''\n",
        "\n",
        "  def __init__(self):\n",
        "    self.q_net = self.build_dqn_model()\n",
        "    self.target_q_net = self.build_dqn_model()\n",
        "\n",
        "  @staticmethod\n",
        "  def build_dqn_model():\n",
        "    '''\n",
        "    Builds deep neural network to predict Q values for all possible actions given a state.\n",
        "    Input should have shape of the state and the output should have the same shape as action space\n",
        "    RETURNS - Q network\n",
        "    '''\n",
        "    q_net = Sequential()\n",
        "    # Adds fully connected layer with 128 units and uses rectified linear unit activation function. he_uniform initliazes weight of layer\n",
        "    q_net.add(Dense(256, input_dim = 82, activation='relu', kernel_initializer='he_uniform'))\n",
        "    q_net.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "    q_net.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "    # 40 actions so 40 different outputs\n",
        "    q_net.add(Dense(24, activation='linear', kernel_initializer='he_uniform'))\n",
        "\n",
        "    # opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    q_net.compile(loss='mse', optimizer = 'adam')\n",
        "    return q_net\n",
        "\n",
        "  def convert_state(self,state):\n",
        "    '''\n",
        "    Convert state into observation variable that can be passed into neural network\n",
        "    PARAM -\n",
        "    state: current game state\n",
        "    RETURNS - observation variable\n",
        "    '''\n",
        "\n",
        "    grid = state.grid_padded.flatten().tolist()\n",
        "    tetromino = state.tetromino_index.flatten().tolist()\n",
        "    # print(grid)\n",
        "    # print(tetromino)\n",
        "    obs_variable = np.asarray(grid+tetromino)\n",
        "    # print(\"Current input dimensions:\")\n",
        "    # print(np.shape(obs_variable))\n",
        "    # print(obs_variable)\n",
        "\n",
        "    return obs_variable\n",
        "\n",
        "\n",
        "  def policy(self,state, curr_epsiode_num):\n",
        "    '''\n",
        "    Takes state from environment and returns an action that has the highest q value using epsilon_greedy\n",
        "    PARAM -\n",
        "    state: current game state\n",
        "    RETURNS - action\n",
        "    '''\n",
        "    # Matches state into array\n",
        "    state_array = self.convert_state(state)\n",
        "    # Convert to into tensorflow tensor\n",
        "    state_input = tf.convert_to_tensor(state_array[None, :], dtype=tf.float32)\n",
        "    # Grabs Q values for all possible actions in current state\n",
        "    action_q = np.array(self.q_net(state_input))\n",
        "    # Allows only legal moves\n",
        "    action_mask = np.array(state.action_mask).flatten()\n",
        "    # Checks if terminal state is reached when there are no more legal moves\n",
        "    terminal = np.where(action_mask)[0]\n",
        "    if len(terminal) == 0:\n",
        "      return False, False\n",
        "    # Calculate epsilon based on the current episode number\n",
        "    epsilon = max(0.001, 1.0 - 0.01 * curr_epsiode_num)  # You can adjust the decay rate\n",
        "    if np.random.rand() < epsilon: # This is the epsilon\n",
        "      action, action_index = self.random_action(state)\n",
        "      return action, action_index\n",
        "    else:\n",
        "      # Legal moves will have a value of 1 while illegal moves have a value of 0\n",
        "      locater = action_mask.astype(int)\n",
        "      # Ensures illegal moves remain illegal\n",
        "      max_q = np.absolute(action_q).max()\n",
        "      action_q[:,locater == 0] -= (max_q + 9999999999)\n",
        "      # Grabs index of action and converts into suitable type\n",
        "      action_index = np.argmax(action_q)\n",
        "      action = unravel(state,action_index)\n",
        "      return action, action_index\n",
        "\n",
        "  def get_valid_actions(self,state):\n",
        "    array = np.array(state.action_mask)\n",
        "    # Flatten the array\n",
        "    flattened_array = array.flatten()\n",
        "    # Get the indices of true values, which are the number of valid actions in the current state\n",
        "    true_indices = np.where(flattened_array)[0]\n",
        "\n",
        "    return true_indices\n",
        "\n",
        "  def random_action(self, state):\n",
        "    array = np.array(state.action_mask)\n",
        "    true_indices = self.get_valid_actions(state)\n",
        "    if len(true_indices) == 0:\n",
        "      return False\n",
        "    random_index = np.random.choice(true_indices)\n",
        "    # Convert the random index to two-dimensional coordinates\n",
        "    rotation, col_index = np.unravel_index(random_index, array.shape)\n",
        "    return [rotation,col_index], random_index\n",
        "\n",
        "  def update_network(self):\n",
        "    '''\n",
        "    Updates current q network with q_net which brings all the training in q_net with target_q_net\n",
        "    '''\n",
        "    self.target_q_net.set_weights(self.q_net.get_weights())\n",
        "\n",
        "  def train(self,batch):\n",
        "    '''\n",
        "    Trains underlying network with batch of gameplay experineces to help it predict Q values\n",
        "    PARAM -\n",
        "    Batch: batch of experiences\n",
        "    RETURNS: Traning loss\n",
        "    '''\n",
        "    # Copying the batch over\n",
        "    state_batch, next_state_batch, reward_batch, action_batch, done_batch = batch\n",
        "    # Running states through the q_net gives output Q values for the states\n",
        "    current_q = self.q_net(state_batch).numpy()\n",
        "    # Copy over Q values for actions that weren't chosen\n",
        "    target_q = np.copy(current_q)\n",
        "    # Get the max Q values of states after transition by running next_state through target_q_net and take max Q values for all actions for each sample\n",
        "    next_q = self.target_q_net(next_state_batch).numpy()\n",
        "    max_next_q = np.amax(next_q, axis=1)\n",
        "    # Update Q value of action taken with max Q value of next state plus intermediate reward from the action taken\n",
        "    for i in range(state_batch.shape[0]):\n",
        "      target_q_val = reward_batch[i].astype(float)\n",
        "      action_index = action_batch[i]\n",
        "      # print(action_index)\n",
        "      if not done_batch[i]:\n",
        "        target_q_val += 0.95 * max_next_q[i]\n",
        "      target_q[i][action_index] = target_q_val\n",
        "    # Train q_net with target Q values\n",
        "    training_his = self.q_net.fit(x = state_batch, y=target_q)\n",
        "    loss = training_his.history['loss']\n",
        "    return loss"
      ],
      "metadata": {
        "id": "q2BxFxyG0ZDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_training(env, agent):\n",
        "  '''\n",
        "  Evaluates performance of DQN agent and calculates average reward\n",
        "  PARAM -\n",
        "  env: game environment\n",
        "  agent: DQN agent\n",
        "  RETURNS: Average reward across episodes\n",
        "  '''\n",
        "  total_reward = 0.0\n",
        "  episodes_to_play = 5\n",
        "  for i in range(episodes_to_play):\n",
        "    key = jax.random.PRNGKey(1)\n",
        "    state, timestep = jax.jit(env.reset)(key)\n",
        "    done = False\n",
        "    episode_reward = 0.0\n",
        "    while not done:\n",
        "      action, action_index = agent.policy(state,999)\n",
        "      if action is False:\n",
        "        done = True\n",
        "        break\n",
        "      next_state, next_timestep = jax.jit(env.step)(state, action)\n",
        "      episode_reward += next_state.reward\n",
        "      state = next_state\n",
        "    total_reward += episode_reward\n",
        "  average_reward = total_reward / episodes_to_play\n",
        "  return average_reward\n",
        "\n",
        "def collect_experiences(env, agent, buffer, curr_episode):\n",
        "  '''\n",
        "  Collect gameplay experiences by playing with env and store experiences in buffer\n",
        "  '''\n",
        "  key = jax.random.PRNGKey(1)\n",
        "  state, timestep = jax.jit(env.reset)(key)\n",
        "  done = False\n",
        "  terminal = False\n",
        "\n",
        "  while not done:\n",
        "    action, action_index = agent.policy(state, curr_episode)\n",
        "    # Testing\n",
        "    #action = agent.random_action(state)\n",
        "    if action is False:\n",
        "      done = True\n",
        "      terminal = True\n",
        "      break\n",
        "    next_state, next_timestep = jax.jit(env.step)(state, action)\n",
        "    buffer.store(agent.convert_state(state), agent.convert_state(next_state), next_state.reward, action_index, terminal)\n",
        "    state = next_state\n",
        "\n",
        "def train_model(max_episodes = 200):\n",
        "  '''\n",
        "  Trains DQN agent to play game\n",
        "  RETURNS: None\n",
        "  '''\n",
        "  save_interval_1 = 50\n",
        "  save_interval_2 = 5\n",
        "  Results = []\n",
        "\n",
        "  # Specify the directory to save the files\n",
        "  save_dir = \"saved_models_and_results\"\n",
        "  if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "  agent = DqnAgent()\n",
        "  buffer = ReplayBuffer()\n",
        "  # Instantiate tetris environment using registry\n",
        "  env = jumanji.make('Tetris-v0', num_rows = 6, num_cols = 6, time_limit = 2000)\n",
        "  # env = jumanji.make('Tetris-v0')\n",
        "\n",
        "\n",
        "  for episode_cnt in range(max_episodes):\n",
        "    print(\"Current episode: {0}\".format(episode_cnt))\n",
        "    collect_experiences(env, agent, buffer, episode_cnt)\n",
        "    gameplay_batch = buffer.sample()\n",
        "    loss = agent.train(gameplay_batch)\n",
        "    print('So far the loss is {0}'.format(loss))\n",
        "    avg_reward = evaluate_training(env, agent)\n",
        "    Results.append(avg_reward)\n",
        "    print('So far the performance is {0}'.format(avg_reward))\n",
        "    # Update target q net every __ episodes (currently 5)\n",
        "    if episode_cnt % 2 == 0:\n",
        "      agent.update_network()\n",
        "    if episode_cnt % save_interval_2 == 0:\n",
        "      print(\"Saving results\")\n",
        "      results_filename = os.path.join(save_dir, f\"results_at_episode_{episode_cnt}.csv\")\n",
        "      with open(results_filename, \"w\") as results_file:\n",
        "        results_file.write(\"Episode,Reward\\n\")\n",
        "        for episode, reward in enumerate(Results, start=1):\n",
        "          results_file.write(f\"{episode},{reward}\\n\")\n",
        "    if episode_cnt % save_interval_1 == 0:\n",
        "      print(\"Saving model\")\n",
        "      # Save best model as an HDF5 model file\n",
        "      DQN_filename = os.path.join(save_dir, f\"DQN_Agent_at_episode_{episode_cnt}.h5\")\n",
        "      agent.q_net.save(DQN_filename)"
      ],
      "metadata": {
        "id": "mzKZfzv80p0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020e702f-3037-4f19-ff5d-4d38a002cf23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()\n",
        "print('No problems')"
      ],
      "metadata": {
        "id": "LttAL5lI0tdK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "52794447-dcf2-4f3f-9f8a-bc90f69f955c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current episode: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 90 calls to <function Model.make_train_function.<locals>.train_function at 0x78d4ca150ca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 380ms/step - loss: 0.5218\n",
            "So far the loss is [0.5218287706375122]\n",
            "So far the performance is 0.0\n",
            "Saving results\n",
            "Saving model\n",
            "Current episode: 1\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8240\n",
            "So far the loss is [6.824009418487549]\n",
            "So far the performance is 0.0\n",
            "Current episode: 2\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.9097\n",
            "So far the loss is [11.909675598144531]\n",
            "So far the performance is 0.0\n",
            "Current episode: 3\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.5733\n",
            "So far the loss is [9.573344230651855]\n",
            "So far the performance is 0.0\n",
            "Current episode: 4\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.4710\n",
            "So far the loss is [7.471009731292725]\n",
            "So far the performance is 40.0\n",
            "Current episode: 5\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3003\n",
            "So far the loss is [8.300277709960938]\n",
            "So far the performance is 40.0\n",
            "Saving results\n",
            "Current episode: 6\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1562\n",
            "So far the loss is [8.156220436096191]\n",
            "So far the performance is 120.0\n",
            "Current episode: 7\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.1711\n",
            "So far the loss is [9.171107292175293]\n",
            "So far the performance is 120.0\n",
            "Current episode: 8\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9814\n",
            "So far the loss is [8.981359481811523]\n",
            "So far the performance is 120.0\n",
            "Current episode: 9\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 8.4998\n",
            "So far the loss is [8.499777793884277]\n",
            "So far the performance is 120.0\n",
            "Current episode: 10\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 7.1772\n",
            "So far the loss is [7.17717981338501]\n",
            "So far the performance is 120.0\n",
            "Saving results\n",
            "Current episode: 11\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 7.0973\n",
            "So far the loss is [7.0973310470581055]\n",
            "So far the performance is 120.0\n",
            "Current episode: 12\n",
            "3/3 [==============================] - 0s 3ms/step - loss: 6.0773\n",
            "So far the loss is [6.07733678817749]\n",
            "So far the performance is 120.0\n",
            "Current episode: 13\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 10.0459\n",
            "So far the loss is [10.045915603637695]\n",
            "So far the performance is 120.0\n",
            "Current episode: 14\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 8.5414\n",
            "So far the loss is [8.541357040405273]\n",
            "So far the performance is 120.0\n",
            "Current episode: 15\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.1972\n",
            "So far the loss is [9.19723129272461]\n",
            "So far the performance is 120.0\n",
            "Saving results\n",
            "Current episode: 16\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 7.2495\n",
            "So far the loss is [7.249499320983887]\n",
            "So far the performance is 120.0\n",
            "Current episode: 17\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 8.8802\n",
            "So far the loss is [8.880196571350098]\n",
            "So far the performance is 0.0\n",
            "Current episode: 18\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 8.6831\n",
            "So far the loss is [8.683059692382812]\n",
            "So far the performance is 0.0\n",
            "Current episode: 19\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 12.5196\n",
            "So far the loss is [12.51962947845459]\n",
            "So far the performance is 0.0\n",
            "Current episode: 20\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 9.1418\n",
            "So far the loss is [9.141818046569824]\n",
            "So far the performance is 0.0\n",
            "Saving results\n",
            "Current episode: 21\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 13.9721\n",
            "So far the loss is [13.972128868103027]\n",
            "So far the performance is 40.0\n",
            "Current episode: 22\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 10.6948\n",
            "So far the loss is [10.694779396057129]\n",
            "So far the performance is 40.0\n",
            "Current episode: 23\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 14.2936\n",
            "So far the loss is [14.293578147888184]\n",
            "So far the performance is 40.0\n",
            "Current episode: 24\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 11.1588\n",
            "So far the loss is [11.158799171447754]\n",
            "So far the performance is 40.0\n",
            "Current episode: 25\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 16.3757\n",
            "So far the loss is [16.37569808959961]\n",
            "So far the performance is 40.0\n",
            "Saving results\n",
            "Current episode: 26\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 14.3376\n",
            "So far the loss is [14.337641716003418]\n",
            "So far the performance is 0.0\n",
            "Current episode: 27\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 18.1839\n",
            "So far the loss is [18.183868408203125]\n",
            "So far the performance is 0.0\n",
            "Current episode: 28\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 15.9308\n",
            "So far the loss is [15.930795669555664]\n",
            "So far the performance is 0.0\n",
            "Current episode: 29\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 24.6114\n",
            "So far the loss is [24.611434936523438]\n",
            "So far the performance is 0.0\n",
            "Current episode: 30\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 17.7465\n",
            "So far the loss is [17.74649429321289]\n",
            "So far the performance is 0.0\n",
            "Saving results\n",
            "Current episode: 31\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 28.2532\n",
            "So far the loss is [28.253204345703125]\n",
            "So far the performance is 0.0\n",
            "Current episode: 32\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 21.8150\n",
            "So far the loss is [21.815021514892578]\n",
            "So far the performance is 0.0\n",
            "Current episode: 33\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 39.7703\n",
            "So far the loss is [39.77030563354492]\n",
            "So far the performance is 0.0\n",
            "Current episode: 34\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 27.7398\n",
            "So far the loss is [27.73981475830078]\n",
            "So far the performance is 0.0\n",
            "Current episode: 35\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 38.8421\n",
            "So far the loss is [38.8420524597168]\n",
            "So far the performance is 0.0\n",
            "Saving results\n",
            "Current episode: 36\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 31.5662\n",
            "So far the loss is [31.566205978393555]\n",
            "So far the performance is 0.0\n",
            "Current episode: 37\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 43.4181\n",
            "So far the loss is [43.418148040771484]\n",
            "So far the performance is 0.0\n",
            "Current episode: 38\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 37.1695\n",
            "So far the loss is [37.1695442199707]\n",
            "So far the performance is 0.0\n",
            "Current episode: 39\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 43.9926\n",
            "So far the loss is [43.99260330200195]\n",
            "So far the performance is 40.0\n",
            "Current episode: 40\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 42.1712\n",
            "So far the loss is [42.171226501464844]\n",
            "So far the performance is 40.0\n",
            "Saving results\n",
            "Current episode: 41\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 60.6904\n",
            "So far the loss is [60.690364837646484]\n",
            "So far the performance is 80.0\n",
            "Current episode: 42\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 51.7264\n",
            "So far the loss is [51.72637176513672]\n",
            "So far the performance is 0.0\n",
            "Current episode: 43\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 67.7565\n",
            "So far the loss is [67.75651550292969]\n",
            "So far the performance is 140.0\n",
            "Current episode: 44\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 52.9254\n",
            "So far the loss is [52.92535400390625]\n",
            "So far the performance is 260.0\n",
            "Current episode: 45\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 99.0413\n",
            "So far the loss is [99.04132080078125]\n",
            "So far the performance is 260.0\n",
            "Saving results\n",
            "Current episode: 46\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 85.7376\n",
            "So far the loss is [85.73762512207031]\n",
            "So far the performance is 140.0\n",
            "Current episode: 47\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 125.5748\n",
            "So far the loss is [125.57484436035156]\n",
            "So far the performance is 140.0\n",
            "Current episode: 48\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 89.1827\n",
            "So far the loss is [89.18267822265625]\n",
            "So far the performance is 140.0\n",
            "Current episode: 49\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 112.9092\n",
            "So far the loss is [112.90921020507812]\n",
            "So far the performance is 260.0\n",
            "Current episode: 50\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 86.1767\n",
            "So far the loss is [86.17670440673828]\n",
            "So far the performance is 140.0\n",
            "Saving results\n",
            "Saving model\n",
            "Current episode: 51\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 109.2712\n",
            "So far the loss is [109.27124786376953]\n",
            "So far the performance is 140.0\n",
            "Current episode: 52\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 132.7854\n",
            "So far the loss is [132.785400390625]\n",
            "So far the performance is 220.0\n",
            "Current episode: 53\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 137.1644\n",
            "So far the loss is [137.16444396972656]\n",
            "So far the performance is 140.0\n",
            "Current episode: 54\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 119.3802\n",
            "So far the loss is [119.3802490234375]\n",
            "So far the performance is 220.0\n",
            "Current episode: 55\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 132.6138\n",
            "So far the loss is [132.61383056640625]\n",
            "So far the performance is 220.0\n",
            "Saving results\n",
            "Current episode: 56\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 118.3235\n",
            "So far the loss is [118.3234634399414]\n",
            "So far the performance is 140.0\n",
            "Current episode: 57\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 158.8960\n",
            "So far the loss is [158.89602661132812]\n",
            "So far the performance is 0.0\n",
            "Current episode: 58\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 130.1778\n",
            "So far the loss is [130.1778106689453]\n",
            "So far the performance is 0.0\n",
            "Current episode: 59\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 148.8035\n",
            "So far the loss is [148.80352783203125]\n",
            "So far the performance is 0.0\n",
            "Current episode: 60\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 176.5680\n",
            "So far the loss is [176.56800842285156]\n",
            "So far the performance is 0.0\n",
            "Saving results\n",
            "Current episode: 61\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 205.9441\n",
            "So far the loss is [205.944091796875]\n",
            "So far the performance is 0.0\n",
            "Current episode: 62\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 185.5366\n",
            "So far the loss is [185.53656005859375]\n",
            "So far the performance is 0.0\n",
            "Current episode: 63\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 265.3799\n",
            "So far the loss is [265.3798828125]\n",
            "So far the performance is 0.0\n",
            "Current episode: 64\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 158.1038\n",
            "So far the loss is [158.10377502441406]\n",
            "So far the performance is 0.0\n",
            "Current episode: 65\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 199.3510\n",
            "So far the loss is [199.3510284423828]\n",
            "So far the performance is 0.0\n",
            "Saving results\n",
            "Current episode: 66\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 248.0662\n",
            "So far the loss is [248.0662078857422]\n",
            "So far the performance is 0.0\n",
            "Current episode: 67\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 252.8732\n",
            "So far the loss is [252.87318420410156]\n",
            "So far the performance is 0.0\n",
            "Current episode: 68\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 278.5743\n",
            "So far the loss is [278.5743408203125]\n",
            "So far the performance is 0.0\n",
            "Current episode: 69\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 319.8246\n",
            "So far the loss is [319.82464599609375]\n",
            "So far the performance is 0.0\n",
            "Current episode: 70\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 282.8304\n",
            "So far the loss is [282.83038330078125]\n",
            "So far the performance is 0.0\n",
            "Saving results\n",
            "Current episode: 71\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 329.8583\n",
            "So far the loss is [329.8582763671875]\n",
            "So far the performance is 0.0\n",
            "Current episode: 72\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 244.4802\n",
            "So far the loss is [244.48020935058594]\n",
            "So far the performance is 0.0\n",
            "Current episode: 73\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 399.6873\n",
            "So far the loss is [399.68731689453125]\n",
            "So far the performance is 0.0\n",
            "Current episode: 74\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 304.1367\n",
            "So far the loss is [304.13665771484375]\n",
            "So far the performance is 0.0\n",
            "Current episode: 75\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 334.9362\n",
            "So far the loss is [334.93621826171875]\n",
            "So far the performance is 0.0\n",
            "Saving results\n",
            "Current episode: 76\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 307.6794\n",
            "So far the loss is [307.679443359375]\n",
            "So far the performance is 0.0\n",
            "Current episode: 77\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 388.8312\n",
            "So far the loss is [388.8312072753906]\n",
            "So far the performance is 0.0\n",
            "Current episode: 78\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 339.3650\n",
            "So far the loss is [339.3649597167969]\n",
            "So far the performance is 0.0\n",
            "Current episode: 79\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 381.2158\n",
            "So far the loss is [381.2158203125]\n",
            "So far the performance is 0.0\n",
            "Current episode: 80\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 355.2379\n",
            "So far the loss is [355.2379455566406]\n",
            "So far the performance is 0.0\n",
            "Saving results\n",
            "Current episode: 81\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 639.7852\n",
            "So far the loss is [639.78515625]\n",
            "So far the performance is 0.0\n",
            "Current episode: 82\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 534.5790\n",
            "So far the loss is [534.5789794921875]\n",
            "So far the performance is 0.0\n",
            "Current episode: 83\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 491.3321\n",
            "So far the loss is [491.33209228515625]\n",
            "So far the performance is 40.0\n",
            "Current episode: 84\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 507.4026\n",
            "So far the loss is [507.402587890625]\n",
            "So far the performance is 32.0\n",
            "Current episode: 85\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 502.5632\n",
            "So far the loss is [502.56317138671875]\n",
            "So far the performance is 40.0\n",
            "Saving results\n",
            "Current episode: 86\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 569.8785\n",
            "So far the loss is [569.8784790039062]\n",
            "So far the performance is 40.0\n",
            "Current episode: 87\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 743.8356\n",
            "So far the loss is [743.8355712890625]\n",
            "So far the performance is 40.0\n",
            "Current episode: 88\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 612.9910\n",
            "So far the loss is [612.9910278320312]\n",
            "So far the performance is 40.0\n",
            "Current episode: 89\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 787.3458\n",
            "So far the loss is [787.3457641601562]\n",
            "So far the performance is 40.0\n",
            "Current episode: 90\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 752.4113\n",
            "So far the loss is [752.4113159179688]\n",
            "So far the performance is 40.0\n",
            "Saving results\n",
            "Current episode: 91\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 795.3875\n",
            "So far the loss is [795.387451171875]\n",
            "So far the performance is 40.0\n",
            "Current episode: 92\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 685.0045\n",
            "So far the loss is [685.0045166015625]\n",
            "So far the performance is 40.0\n",
            "Current episode: 93\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 758.4298\n",
            "So far the loss is [758.4298095703125]\n",
            "So far the performance is 40.0\n",
            "Current episode: 94\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 916.4900\n",
            "So far the loss is [916.489990234375]\n",
            "So far the performance is 40.0\n",
            "Current episode: 95\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1083.9276\n",
            "So far the loss is [1083.9276123046875]\n",
            "So far the performance is 40.0\n",
            "Saving results\n",
            "Current episode: 96\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 798.7729\n",
            "So far the loss is [798.77294921875]\n",
            "So far the performance is 40.0\n",
            "Current episode: 97\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 780.5305\n",
            "So far the loss is [780.5304565429688]\n",
            "So far the performance is 40.0\n",
            "Current episode: 98\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 738.1971\n",
            "So far the loss is [738.1971435546875]\n",
            "So far the performance is 40.0\n",
            "Current episode: 99\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1127.5648\n",
            "So far the loss is [1127.5648193359375]\n",
            "So far the performance is 40.0\n",
            "Current episode: 100\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 1100.2395\n",
            "So far the loss is [1100.239501953125]\n",
            "So far the performance is 40.0\n",
            "Saving results\n",
            "Saving model\n",
            "Current episode: 101\n",
            "4/4 [==============================] - 0s 4ms/step - loss: 713.1755\n",
            "So far the loss is [713.1754760742188]\n",
            "So far the performance is 40.0\n",
            "Current episode: 102\n",
            "4/4 [==============================] - 0s 3ms/step - loss: 840.5250\n",
            "So far the loss is [840.5249633789062]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-0b8107b5e824>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No problems'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-7b5a8a14bde1>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(max_episodes)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgameplay_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'So far the loss is {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mavg_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mResults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'So far the performance is {0}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-7b5a8a14bde1>\u001b[0m in \u001b[0;36mevaluate_training\u001b[0;34m(env, agent)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m       \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_timestep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m       \u001b[0mepisode_reward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcache_miss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m     outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(\n\u001b[0m\u001b[1;32m    254\u001b[0m         fun, infer_params_fn, *args, **kwargs)\n\u001b[1;32m    255\u001b[0m     \u001b[0mexecutable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_most_recent_pjit_call_executable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_python_pjit_helper\u001b[0;34m(fun, infer_params_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m     \u001b[0mout_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpjit_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mpxla\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeviceAssignmentMismatchError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mfails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m   2594\u001b[0m     top_trace = (top_trace if not axis_main or axis_main.level < top_trace.level\n\u001b[1;32m   2595\u001b[0m                  else axis_main.with_cur_sublevel())\n\u001b[0;32m-> 2596\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mbind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind_with_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 821\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_call_impl\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1207\u001b[0m       in_shardings, out_shardings, None, None)\n\u001b[1;32m   1208\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mxla_extension_version\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m169\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1209\u001b[0;31m     return xc._xla.pjit(name, f, call_impl_cache_miss, [], [], donated_argnums,\n\u001b[0m\u001b[1;32m   1210\u001b[0m                         \u001b[0mtree_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_registry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1211\u001b[0m                         _get_cpp_global_cache(has_explicit_sharding))(*args)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36mcall_impl_cache_miss\u001b[0;34m(*args_, **kwargs_)\u001b[0m\n\u001b[1;32m   1190\u001b[0m                     donated_invars, name, keep_unused, inline):\n\u001b[1;32m   1191\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_impl_cache_miss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m     out_flat, compiled = _pjit_call_impl_python(\n\u001b[0m\u001b[1;32m   1193\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0min_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0mout_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresource_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_call_impl_python\u001b[0;34m(jaxpr, in_shardings, out_shardings, resource_env, donated_invars, name, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1123\u001b[0m       resource_env.physical_mesh if resource_env is not None else None)\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m   compiled = _pjit_lower(\n\u001b[0m\u001b[1;32m   1126\u001b[0m       \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_env\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0mdonated_invars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_unused\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lower\u001b[0;34m(jaxpr, in_shardings, out_shardings, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1257\u001b[0m   \u001b[0min_shardings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSameDeviceAssignmentTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_shardings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m   \u001b[0mout_shardings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSameDeviceAssignmentTuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shardings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pjit_lower_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lower_cached\u001b[0;34m(jaxpr, sdat_in_shardings, sdat_out_shardings, resource_env, donated_invars, name, keep_unused, inline, always_lower, lowering_platform, override_lowering_rules)\u001b[0m\n\u001b[1;32m   1299\u001b[0m       lowering_platform=lowering_platform)\n\u001b[1;32m   1300\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m     return pxla.lower_sharding_computation(\n\u001b[0m\u001b[1;32m   1302\u001b[0m         \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdonated_invars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36mlower_sharding_computation\u001b[0;34m(fun_or_jaxpr, api_name, fun_name, in_shardings, out_shardings, donated_invars, global_in_avals, keep_unused, inline, always_lower, devices_from_context, lowering_platform, override_lowering_rules)\u001b[0m\n\u001b[1;32m   1966\u001b[0m   \u001b[0msemantic_out_shardings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSemanticallyEqualShardings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shardings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1967\u001b[0m   (module, keepalive, host_callbacks, unordered_effects, ordered_effects,\n\u001b[0;32m-> 1968\u001b[0;31m    \u001b[0mnreps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_poly_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cached_lowering_to_hlo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1969\u001b[0m        \u001b[0mclosed_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msemantic_in_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1970\u001b[0m        \u001b[0msemantic_out_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mda_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowering_platform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/pxla.py\u001b[0m in \u001b[0;36m_cached_lowering_to_hlo\u001b[0;34m(closed_jaxpr, api_name, fun_name, backend, semantic_in_shardings, semantic_out_shardings, da_object, lowering_platform, donated_invars, name_stack, override_lowering_rules)\u001b[0m\n\u001b[1;32m   1806\u001b[0m         \u001b[0;34m\"Finished jaxpr to MLIR module conversion {fun_name} in {elapsed_time} sec\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m         fun_name=str(name_stack), event=dispatch.JAXPR_TO_MLIR_MODULE_EVENT):\n\u001b[0;32m-> 1808\u001b[0;31m     lowering_result = mlir.lower_jaxpr_to_module(\n\u001b[0m\u001b[1;32m   1809\u001b[0m         \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1810\u001b[0m         \u001b[0mclosed_jaxpr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_module\u001b[0;34m(module_name, jaxpr, ordered_effects, backend_or_name, platform, axis_context, name_stack, donated_args, replicated_args, arg_shardings, result_shardings, arg_names, result_names, num_replicas, num_partitions, override_lowering_rules)\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mhlo.num_replicas\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi32_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_replicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mhlo.num_partitions\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi32_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_partitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m     lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m    730\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mordered_effects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m         \u001b[0mreplace_tokens_with_dummy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1071\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1225\u001b[0m                          for d in a.shape if type(d) is core.Var}\n\u001b[1;32m   1226\u001b[0m         \u001b[0mrule_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrule_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis_size_env\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m       ans = rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes),\n\u001b[0m\u001b[1;32m   1228\u001b[0m                  **eqn.params)\n\u001b[1;32m   1229\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/pjit.py\u001b[0m in \u001b[0;36m_pjit_lowering\u001b[0;34m(ctx, name, jaxpr, in_shardings, out_shardings, resource_env, donated_invars, keep_unused, inline, *args)\u001b[0m\n\u001b[1;32m   1383\u001b[0m   \u001b[0;31m# inputs or outputs because they are lost during MLIR->HLO conversion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m   \u001b[0;31m# using_sharding_annotation=False means we add an identity operation instead.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m   func = mlir.lower_jaxpr_to_fun(\n\u001b[0m\u001b[1;32m   1386\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meffects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_shardings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m       \u001b[0mresult_shardings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult_shardings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_sharding_annotations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mlower_jaxpr_to_fun\u001b[0;34m(ctx, name, jaxpr, effects, create_tokens, public, replace_tokens_with_dummy, replicated_args, arg_shardings, result_shardings, use_sharding_annotations, input_output_aliases, num_output_tokens, api_name, arg_names, result_names)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \u001b[0mcallee_name_stack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m     out_vals, tokens_out = jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack),\n\u001b[0m\u001b[1;32m   1071\u001b[0m                                          \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mir_constants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m                                          *args, dim_var_values=dim_var_values)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36mjaxpr_subcomp\u001b[0;34m(ctx, jaxpr, tokens, consts, dim_var_values, *args)\u001b[0m\n\u001b[1;32m   1193\u001b[0m     source_info = eqn.source_info.replace(\n\u001b[1;32m   1194\u001b[0m         name_stack=ctx.name_stack + eqn.source_info.name_stack)\n\u001b[0;32m-> 1195\u001b[0;31m     loc = _source_info_to_location(eqn.primitive, eqn.params, source_info,\n\u001b[0m\u001b[1;32m   1196\u001b[0m                                    ctx.name_stack)\n\u001b[1;32m   1197\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msource_info_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/interpreters/mlir.py\u001b[0m in \u001b[0;36m_source_info_to_location\u001b[0;34m(primitive, params, source_info, name_stack)\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_traceback_to_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_info_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m       \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/source_info_util.py\u001b[0m in \u001b[0;36muser_frame\u001b[0;34m(source_info)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0muser_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSourceInfo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFrame\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_summarize_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFrame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/source_info_util.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m   \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlasti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtraceback\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m   return (raw_frame_to_frame(code[i], lasti[i]) for i in range(len(code))  # type: ignore\n\u001b[0;32m--> 160\u001b[0;31m           if is_user_filename(code[i].co_filename))\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlru_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/jax/_src/source_info_util.py\u001b[0m in \u001b[0;36mis_user_filename\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mSourceInfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNameStack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_user_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m   \u001b[0;34m\"\"\"Heuristic that guesses the identity of the user's code in a stack trace.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m   return (filename.endswith(\"_test.py\") or\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uZq55IOnzdSo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}