{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "toc_visible": true,
      "mount_file_id": "1WKgnsRajh4wSsbwjl49a5oH9sjCcC0Uw",
      "authorship_tag": "ABX9TyPdQIQdHsKNG23epSIIe0Jh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zhi-704/ERL/blob/master/Tetris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install jumanji"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnpGC6_MlLFm",
        "outputId": "dc4afa68-e715-4cb5-d452-05371d93e379"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting jumanji\n",
            "  Downloading jumanji-0.3.1.tar.gz (583 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m583.5/583.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chex>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from jumanji) (0.1.7)\n",
            "Collecting dm-env>=1.5 (from jumanji)\n",
            "  Downloading dm_env-1.6-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: gym>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from jumanji) (0.25.2)\n",
            "Requirement already satisfied: jax>=0.2.26 in /usr/local/lib/python3.10/dist-packages (from jumanji) (0.4.13)\n",
            "Requirement already satisfied: matplotlib>=3.3.4 in /usr/local/lib/python3.10/dist-packages (from jumanji) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from jumanji) (1.22.4)\n",
            "Requirement already satisfied: Pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from jumanji) (9.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from jumanji) (4.7.1)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.3->jumanji) (1.4.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.3->jumanji) (0.1.8)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.3->jumanji) (0.4.13+cuda11.cudnn86)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.3->jumanji) (0.12.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym>=0.22.0->jumanji) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym>=0.22.0->jumanji) (0.0.8)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.26->jumanji) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.26->jumanji) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.2.26->jumanji) (1.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (23.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.4->jumanji) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.4->jumanji) (1.16.0)\n",
            "Building wheels for collected packages: jumanji\n",
            "  Building wheel for jumanji (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jumanji: filename=jumanji-0.3.1-py3-none-any.whl size=750386 sha256=11a7012eb2f8ac0350847c8e0b5cc74d2fd43f2db19e0d155a339b0da50893ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/29/10/884df072d319d2522cfff8b9c3d61fe60ab3c31e2a054d3e5d\n",
            "Successfully built jumanji\n",
            "Installing collected packages: dm-env, jumanji\n",
            "Successfully installed dm-env-1.6 jumanji-0.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import jumanji\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "import random\n",
        "# import cv2\n",
        "from collections import namedtuple, deque\n",
        "# from itertools import count\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "# import torch.nn.functional as F\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# from PIL import Image\n",
        "from time import sleep"
      ],
      "metadata": {
        "id": "2Fed9VeileQN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate tetris environment using registry\n",
        "\n",
        "env = jumanji.make('Tetris-v0', num_rows = 5, time_limit = 1000)\n",
        "\n",
        "# Reset your (jit-able) environment\n",
        "key = jax.random.PRNGKey(1)\n",
        "state, timestep = jax.jit(env.reset)(key)\n",
        "\n",
        "env.render(state)\n",
        "print(state.reward)\n",
        "print(state)\n",
        "\n",
        "grid = state.grid_padded.flatten().tolist()\n",
        "tetromino = state.tetromino_index.flatten().tolist()\n",
        "print(grid)\n",
        "print(tetromino)\n",
        "obs_variable = np.asarray(grid+tetromino)\n",
        "print(np.shape(obs_variable))\n",
        "print(obs_variable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6MrqvLFsoJBw",
        "outputId": "102f3d62-f95e-4eb3-baab-f169ad652b70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "State(grid_padded=Array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32), grid_padded_old=Array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32), tetromino_index=Array(6, dtype=int32), old_tetromino_rotated=Array([[0, 1, 0, 0],\n",
            "       [0, 1, 0, 0],\n",
            "       [1, 1, 0, 0],\n",
            "       [0, 0, 0, 0]], dtype=int32), new_tetromino=Array([[0, 1, 0, 0],\n",
            "       [0, 1, 0, 0],\n",
            "       [1, 1, 0, 0],\n",
            "       [0, 0, 0, 0]], dtype=int32), x_position=Array(0, dtype=int32), y_position=Array(0, dtype=int32), action_mask=Array([[ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "        False],\n",
            "       [ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
            "        False],\n",
            "       [ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "        False],\n",
            "       [ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
            "        False]], dtype=bool), full_lines=Array([False, False, False, False, False, False, False, False], dtype=bool), score=Array(0., dtype=float32), reward=Array(0., dtype=float32), key=Array([0, 1], dtype=uint32), is_reset=Array(True, dtype=bool), step_count=Array(0, dtype=int32))\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[6]\n",
            "(105,)\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action = env.action_spec().generate_value()          # Action selection (dummy value here)\n",
        "\n",
        "num_actions = state.action_mask.shape[0] * state.action_mask.shape[1]\n",
        "\n",
        "while not done:\n",
        "  array = np.array(state.action_mask)\n",
        "  # Flatten the array\n",
        "  flattened_array = array.flatten()\n",
        "  # Get the indices of True values\n",
        "  true_indices = np.where(flattened_array)[0]\n",
        "  random_index = np.random.choice(true_indices)\n",
        "  # Convert the random index to two-dimensional coordinates\n",
        "  row_index, col_index = np.unravel_index(random_index, array.shape)\n",
        "  action = [row_index, col_index]\n",
        "\n",
        "  state, timestep = jax.jit(env.step)(state, action)   # Take a step and observe the next state and time step\n",
        "\n",
        "  env.render(state)\n",
        "\n",
        "print(state.action_mask)\n",
        "\n",
        "# env.render(state)\n",
        "# print(array)\n",
        "# print(\"LINE1\")\n",
        "# print(flattened_array)\n",
        "# print(\"LINE2\")\n",
        "# print(true_indices)\n",
        "# print(\"LINE3\")\n",
        "# print(row_index, col_index)\n",
        "# print(\"LINE4\")\n",
        "# print(state.reward)\n",
        "# print(state.grid_padded)\n",
        "# print(state.new_tetromino)\n",
        "\n",
        "tetromino = state.tetromino_index.flatten()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        },
        "id": "ripsVBQEpzxZ",
        "outputId": "9e5998e1-08e2-46d0-85f9-7bb5fd72f65a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[False False False False False False False False False False]\n",
            " [False False False False False False False False False False]\n",
            " [False False False False False False False False False False]\n",
            " [False False False False False False False False False False]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env.render(state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "djmI6deg7thQ",
        "outputId": "a36700af-953c-40cf-ad0c-f5de4a389c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_action(state):\n",
        "  array = np.array(state.action_mask)\n",
        "  # Flatten the array\n",
        "  flattened_array = array.flatten()\n",
        "  # Get the indices of True values\n",
        "  true_indices = np.where(flattened_array)[0]\n",
        "  if len(true_indices) == 0:\n",
        "   return False\n",
        "  random_index = np.random.choice(true_indices)\n",
        "  # Convert the random index to two-dimensional coordinates\n",
        "  rotation, col_index = np.unravel_index(random_index, array.shape)\n",
        "  return [rotation,col_index]"
      ],
      "metadata": {
        "id": "g5RB-zIMqkKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters for algorithm and agents generated\n",
        "epsilon = 0.01\n",
        "discount_factor = 0.99\n",
        "learning_rate = 0.20\n",
        "planningsteps = 0\n",
        "\n",
        "def get_valid_actions(state):\n",
        "  array = np.array(state.action_mask)\n",
        "  # Flatten the array\n",
        "  flattened_array = array.flatten()\n",
        "  # Get the indices of true values, which are the number of valid actions in the current state\n",
        "  true_indices = np.where(flattened_array)[0]\n",
        "\n",
        "  return true_indices\n",
        "\n",
        "def choose_action(Qvalues,state, state_tuple):\n",
        "  # # Makes sure the algorithm does not always pick the first index if all index values are the same\n",
        "  # if np.all(Qvalues[state] == Qvalues[state][0]):\n",
        "  #   return [(np.random.randint(0,3)), (np.random.randint(0,9))]\n",
        "  valid_actions = get_valid_actions(state)\n",
        "  if len(valid_actions) == 0:\n",
        "    return False\n",
        "  # Choose action with epsilon-greedy policy\n",
        "  if np.random.uniform(0,1) < epsilon:\n",
        "    action_index = np.random.choice(valid_actions, size = 1)\n",
        "  else:\n",
        "    # Access array associated with the state key and find the index of the maximum value\n",
        "    index_with_highest_Q_value = np.argmax(Qvalues[state_tuple][:, 1])\n",
        "    # Take only the valid action\n",
        "    action_index = Qvalues[state_tuple][index_with_highest_Q_value, 0]\n",
        "\n",
        "  # Convert the action index to two-dimensional coordinates\n",
        "  rotation, col_index = np.unravel_index(action_index, array.shape)\n",
        "\n",
        "  return [rotation, col_index], action_index\n",
        "\n",
        "\n",
        "def Qalgorithm(Qvalues):\n",
        "\n",
        "  # Initialises environment and rewards\n",
        "  rewards = []\n",
        "  # Reset your (jit-able) environment\n",
        "  key = jax.random.PRNGKey(0)\n",
        "  state, timestep = jax.jit(env.reset)(key)\n",
        "  state_tuple = tuple(state)\n",
        "\n",
        "  env.render(state)\n",
        "\n",
        "  valid_actions = get_valid_actions(state)\n",
        "\n",
        "  # Adds new state to Q values tables and model\n",
        "  if state_tuple not in Qvalues:\n",
        "    corresponding_array = [[x, 0] for x in valid_actions]\n",
        "    Qvalues.update({state_tuple: corresponding_array})\n",
        "\n",
        "  print(\"STATE UPDATED FIRST\")\n",
        "  print(Qvalues[state_tuple])\n",
        "\n",
        "  while True:\n",
        "\n",
        "    # Chooses max value action and takes the action\n",
        "    chosen_action, action_index = choose_action(Qvalues, state, state_tuple)\n",
        "    print(\"ACTION CHOSEN\")\n",
        "    # next_state, reward, terminal = env.step(chosen_action)\n",
        "    next_state, timestep = jax.jit(env.step)(state, chosen_action)\n",
        "    next_state_tuple = tuple(next_state)\n",
        "    curr_reward = next_state.reward\n",
        "\n",
        "    print(\"NEXT STATE UPDATED\")\n",
        "\n",
        "    new_valid_actions = get_valid_actions(next_state)\n",
        "    # Adds new state to Q values and Model\n",
        "    if next_state_tuple not in Qvalues:\n",
        "      corresponding_array2 = [[x,0] for x in new_valid_actions]\n",
        "      Qvalues.update({next_state_tuple: corresponding_array2})\n",
        "\n",
        "    print(\"NEXT STATE UPDATED SECOND\")\n",
        "    print(Qvalues[next_state_tuple])\n",
        "\n",
        "    # Adds reward to prior reward\n",
        "    rewards.append(curr_reward)\n",
        "\n",
        "    # Locates action index\n",
        "    chosen_action_index = np.where(Qvalues[state_tuple][:,0] == action_index)[0]\n",
        "\n",
        "    # Updates Q value table\n",
        "    Qvalues[state_tuple][chosen_action_index][1] += learning_rate * (curr_reward + discount_factor * np.max(Qvalues[next_state_tuple][:, 1]) - Qvalues[state_tuple][chosen_action_index][1])\n",
        "    print(\"Q VALUE UPDATED\")\n",
        "    print(Qvalues[state_tuple])\n",
        "    # Ends episode once terminal state is reached\n",
        "    if chosen_action is False:\n",
        "        break\n",
        "\n",
        "    print(\"TERMINAL PASSED\")\n",
        "    state = next_state\n",
        "    state_tuple = next_state_tuple\n",
        "\n",
        "    time.sleep(3)\n",
        "\n",
        "    env.render(state)\n",
        "\n",
        "\n",
        "  return sum(rewards)\n"
      ],
      "metadata": {
        "id": "qRA-1bverBd2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0f6485b-e40b-494d-b946-657dfadd05e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RandomAgent():\n",
        "  key = jax.random.PRNGKey(0)\n",
        "  state, timestep = jax.jit(env.reset)(key)\n",
        "\n",
        "  for i in range(50):\n",
        "    action = get_action(state)\n",
        "    print(action)\n",
        "    if action == False:\n",
        "      key = jax.random.PRNGKey(0)\n",
        "      state, timestep = jax.jit(env.reset)(key)\n",
        "      print(\"Environment Reset\")\n",
        "      continue\n",
        "    state, timestep = jax.jit(env.step)(state, action)\n",
        "    env.render(state)\n",
        "\n",
        "RandomAgent()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "WWPDBM-Sql_D",
        "outputId": "2f8df6e0-f366-4c71-d9e5-37e65f69f847",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8974a51d7c76>\u001b[0m in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mQvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mRandomAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-8974a51d7c76>\u001b[0m in \u001b[0;36mRandomAgent\u001b[0;34m(Qvalues)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_tuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-7e17c0f124f3>\u001b[0m in \u001b[0;36mchoose_action\u001b[0;34m(Qvalues, state, state_tuple)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0;31m# Access array associated with the state key and find the index of the maximum value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m   \u001b[0maction_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate_tuple\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0;31m# Convert the action index to two-dimensional coordinates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: ('grid_padded', 'grid_padded_old', 'tetromino_index', 'old_tetromino_rotated', 'new_tetromino', 'x_position', 'y_position', 'action_mask', 'full_lines', 'score', 'reward', 'key', 'is_reset', 'step_count')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_agents = 1\n",
        "\n",
        "def generateagent(episodes):\n",
        "  # Resets Q values and Model table\n",
        "  Qvalues = {}\n",
        "  # Generates an agent that follows QLearning for a number of episodes\n",
        "  total_rewards = np.zeros(episodes)\n",
        "  for i in range(len(total_rewards)):\n",
        "      total_rewards[i] = Qalgorithm(Qvalues)\n",
        "  return total_rewards\n",
        "\n",
        "\n",
        "# modified_agent_rewards = []\n",
        "# for i in range(num_of_agents):\n",
        "#   agent = generateagent()\n",
        "#   print(\"Agent\",i+1, \"has been generated\")\n",
        "#   modified_agent_rewards.append([])\n",
        "#   modified_agent_rewards[i].extend(agent)\n",
        "\n",
        "# print(\"ALL AGENTS HAVE BEEN GENERATED\")"
      ],
      "metadata": {
        "id": "3moK4xW_nR15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episodes = 3\n",
        "\n",
        "total_rewards, Qvalues = generateagent(episodes)\n",
        "\n",
        "# Plot the rewards over episodes\n",
        "plt.plot(range(1, episodes + 1), total_rewards)\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Total Reward')\n",
        "plt.title('Agent Performance over Episodes')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S1n0SOo2xt1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "1- Initialize replay memory capacity.\n",
        "2- Initialize the policy network with random weights.\n",
        "3- Clone the policy network, and call it the target network (target_model).\n",
        "4- For each episode:\n",
        "    1. Initialize the starting state.\n",
        "    2. For each time step:\n",
        "        1- Select an action.\n",
        "            - Via exploration or exploitation, which depends on epsilon.\n",
        "        2- Execute selected action in an emulator (the environment).\n",
        "        3- Observe reward and next state.\n",
        "        4- Store experience in replay memory.\n",
        "        5- Sample random batch from replay memory.\n",
        "        6- Preprocess states from batch (normalization).\n",
        "        7- Pass batch of preprocessed states to policy network.\n",
        "        8- Calculate loss between output Q-values and target Q-values.\n",
        "            - Requires a pass to the target network for the next state\n",
        "        9- Gradient descent updates weights in the policy network to minimize loss.\n",
        "            - After x time steps, weights in the target network are updated to the weights in the policy network.\n",
        "  '''"
      ],
      "metadata": {
        "id": "veOavTTKmHqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if torch.cuda.is_available():\n",
        "  print(\"Using GPU\")\n",
        "  FloatTensor = torch.cuda.FloatTensor\n",
        "  LongTensor = torch.cuda.LongTensor\n",
        "  ByteTensor = torch.cuda.ByteTensor\n",
        "  num_episodes = 600\n",
        "else:\n",
        "  print(\"Using CPU\")\n",
        "  FloatTensor = torch.FloatTensor\n",
        "  LongTensor = torch.LongTensor\n",
        "  ByteTensor = torch.ByteTensor\n",
        "  num_episodes = 1\n",
        "\n",
        "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "# Replay buffer to store experience\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "      self.capacity = capacity\n",
        "      self.memory = deque([], maxlen=capacity)\n",
        "      self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)\n",
        "\n",
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# TAU is the update rate of the target network\n",
        "# LR is the learning rate of the ``AdamW`` optimizer\n",
        "BATCH_SIZE = 64\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 800\n",
        "TAU = 0.005\n",
        "LR = 1e-4\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "# Get the number of state observations\n",
        "state, info = env.reset()\n",
        "n_observations = len(state)\n",
        "\n",
        "policy_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "\n",
        "    # Random number generated to decide whether to explore or exploit\n",
        "    sample = random.random()\n",
        "\n",
        "    # Epsilon threshold calculated as a function of epsilon decay over steps done\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "\n",
        "    # Get valid actions from current state\n",
        "    valid_actions = get_valid_actions(state)\n",
        "    array = np.array(state.action_mask)\n",
        "\n",
        "    if sample > eps_threshold:\n",
        "      with torch.no_grad():\n",
        "        # Get the Q-values for each action in the state\n",
        "        # NEED TO FIX\n",
        "        q_values = policy_net(state)[valid_actions]\n",
        "        # Find the action index with the maximum Q-value\n",
        "        action_index = valid_actions[q_values.argmax()]\n",
        "        # Convert the action index to the corresponding rotation and column\n",
        "        rotation, col_index = np.unravel_index(action_index, array.shape)\n",
        "        return torch.tensor([[rotation, column]], device=device, dtype=torch.long)\n",
        "    else:\n",
        "      # Randomly sample an action from the environment's action space\n",
        "      action_index = np.random.choice(valid_actions, size = 1)\n",
        "      # Convert the action index to two-dimensional coordinates\n",
        "      rotation, col_index = np.unravel_index(action_index, array.shape)\n",
        "      return torch.tensor([[rotation, col_index]], device=device, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "NQ8A2rAQvMrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "jnrVb4p_1z85"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "episode_durations = []\n",
        "\n",
        "\n",
        "def plot_durations(show_result=False):\n",
        "    plt.figure(1)\n",
        "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(durations_t.numpy())\n",
        "    # Take 100 episode averages and plot them too\n",
        "    if len(durations_t) >= 100:\n",
        "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
        "        means = torch.cat((torch.zeros(99), means))\n",
        "        plt.plot(means.numpy())\n",
        "\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())"
      ],
      "metadata": {
        "id": "OFtIGOuJ10Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.memory = deque(maxlen=1000)\n",
        "    self.capacity = 1000\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.memory)\n",
        "\n",
        "  def store(self, state, next_state, reward, action, done):\n",
        "    '''\n",
        "    Records a single step of game play experience\n",
        "    PARAM -\n",
        "    state: current game state\n",
        "    next_state: game state after taking action\n",
        "    reard: reward taking action at the current state brings\n",
        "    action: action taken at the current state\n",
        "    done: boolean to indicate if game is finished after taking action\n",
        "    RETURNS - N/A\n",
        "    '''\n",
        "    if len(self.memory) > self.capacity:\n",
        "      del self.memory[0]\n",
        "    self.memory.append((state, next_state, reward, action, done))\n",
        "\n",
        "\n",
        "  def sample(self):\n",
        "    '''\n",
        "    Samples a batch of gameplay experiences for training\n",
        "    PARAM - None\n",
        "    RETURNS - list of gameplay experiences\n",
        "    '''\n",
        "    batch_size = min(128, len(self.memory))\n",
        "    sample_batch = random.sample(self.memory, batch_size)\n",
        "    state_batch = []\n",
        "    next_state_batch = []\n",
        "    reward_batch = []\n",
        "    action_batch = []\n",
        "    done_batch = []\n",
        "    for experience in sample_batch:\n",
        "      state_batch.append(experience[0])\n",
        "      next_state_batch.append(experience[1])\n",
        "      reward_batch.append(experience[2])\n",
        "      action_batch.append(experience[3])\n",
        "      done_batch.append(experience[4])\n",
        "\n",
        "    return  np.array(state_batch), np.array(next_state_batch), np.array(reward_batch), np.array(action_batch), np.array(done_batch)"
      ],
      "metadata": {
        "id": "d7cewx2tPvxD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow import keras\n",
        "\n",
        "class DqnAgent:\n",
        "  '''\n",
        "\n",
        "  '''\n",
        "\n",
        "  def __init__(self):\n",
        "    self.q_net = self.build_dqn_model()\n",
        "    self.target_q_net = self.build_dqn_model()\n",
        "\n",
        "  @staticmethod\n",
        "  def build_dqn_model():\n",
        "    '''\n",
        "    Builds deep neural network to predict Q values for all possible actions given a state.\n",
        "    Input should have shape of the state and the output should have the same shape as action space\n",
        "    RETURNS - Q network\n",
        "    '''\n",
        "    q_net = Sequential()\n",
        "    # Adds fully connected layer with 128 units and uses rectified linear unit activation function. he_uniform initliazes weight of layer\n",
        "    q_net.add(Dense(128, input_dim = 105, activation='relu', kernel_initializer='he_uniform'))\n",
        "    q_net.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))\n",
        "    q_net.add(Dense(40, activation='linear', kernel_initializer='he_uniform'))\n",
        "\n",
        "    # opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "    q_net.compile(loss='mse', optimizer = 'adam')\n",
        "    return q_net\n",
        "\n",
        "  def convert_state(self,state):\n",
        "    '''\n",
        "    Convert state into observation variable that can be passed into neural network\n",
        "    PARAM -\n",
        "    state: current game state\n",
        "    RETURNS - observation variable\n",
        "    '''\n",
        "\n",
        "    grid = state.grid_padded.flatten().tolist()\n",
        "    tetromino = state.tetromino_index.flatten().tolist()\n",
        "    # print(grid)\n",
        "    # print(tetromino)\n",
        "    obs_variable = np.asarray(grid+tetromino)\n",
        "    # print(\"Current input dimensions:\")\n",
        "    # print(np.shape(obs_variable))\n",
        "    # print(obs_variable)\n",
        "\n",
        "    return obs_variable\n",
        "\n",
        "\n",
        "  def policy(self,state):\n",
        "    '''\n",
        "    Takes state from environment and returns an action that has the highest q value using epsilon_greedy\n",
        "    PARAM -\n",
        "    state: current game state\n",
        "    RETURNS - action\n",
        "    '''\n",
        "    # Matches state into 105, array\n",
        "    state_array = self.convert_state(state)\n",
        "    # Convert to into tensorflow tensor\n",
        "    state_input = tf.convert_to_tensor(state_array[None, :], dtype=tf.float32)\n",
        "    # Grabs Q values for all possible actions in current state\n",
        "    action_q = self.q_net(state_input)\n",
        "\n",
        "    action_mask = np.array(state.action_mask).flatten()\n",
        "\n",
        "    valid_q_values = action_q * action_mask\n",
        "    # Set elements that are zero to -999\n",
        "    valid_q_values = np.where(valid_q_values == 0, -999, valid_q_values)\n",
        "\n",
        "    print(\"ACTION MASK\")\n",
        "    print(action_mask)\n",
        "    print(\"CORRESPONDING Q VALUES\")\n",
        "    print(valid_q_values)\n",
        "    # print(np.shape(valid_q_values))\n",
        "    true_indices = self.get_valid_actions(state)\n",
        "    print(true_indices)\n",
        "    if len(true_indices) == 0:\n",
        "      return False, False\n",
        "    else:\n",
        "      action_index = np.argmax(valid_q_values, axis=1)[0]\n",
        "      # Convert action into acceptable type\n",
        "      array = np.array(state.action_mask)\n",
        "      rotation, col_index = np.unravel_index(action_index, array.shape)\n",
        "      action = [rotation, col_index]\n",
        "      return action, action_index\n",
        "\n",
        "  def get_valid_actions(self,state):\n",
        "    array = np.array(state.action_mask)\n",
        "    # Flatten the array\n",
        "    flattened_array = array.flatten()\n",
        "    # Get the indices of true values, which are the number of valid actions in the current state\n",
        "    true_indices = np.where(flattened_array)[0]\n",
        "\n",
        "    return true_indices\n",
        "\n",
        "  def random_action(self, state):\n",
        "    array = np.array(state.action_mask)\n",
        "    true_indices = self.get_valid_actions(state)\n",
        "    if len(true_indices) == 0:\n",
        "      return False\n",
        "    random_index = np.random.choice(true_indices)\n",
        "    # Convert the random index to two-dimensional coordinates\n",
        "    rotation, col_index = np.unravel_index(random_index, array.shape)\n",
        "    return [rotation,col_index]\n",
        "\n",
        "  def update_network(self):\n",
        "    '''\n",
        "    Updates current q network with q_net which brings all the training in q_net with target_q_net\n",
        "    '''\n",
        "    self.target_q_net.set_weights(self.q_net.get_weights())\n",
        "\n",
        "  def train(self,batch):\n",
        "    '''\n",
        "    Trains underlying network with batch of gameplay experineces to help it predict Q values\n",
        "    PARAM -\n",
        "    Batch: batch of experiences\n",
        "    RETURNS: Traning loss\n",
        "    '''\n",
        "    # Copying the batch over\n",
        "    state_batch, next_state_batch, reward_batch, action_batch, done_batch = batch\n",
        "\n",
        "    print(state_batch)\n",
        "    print(next_state_batch)\n",
        "    print(\"REWARD\")\n",
        "    print(reward_batch)\n",
        "    print(\"ACTION\")\n",
        "    print(action_batch)\n",
        "    print(done_batch)\n",
        "\n",
        "    # Running states through the q_net gives output Q values for the states\n",
        "    current_q = self.q_net(state_batch).numpy()\n",
        "    print(\"Printing current q\")\n",
        "    print(current_q)\n",
        "    # Copy over Q values for actions that weren't chosen\n",
        "    target_q = np.copy(current_q)\n",
        "    print(\"Printing target q\")\n",
        "    print(np.shape(target_q))\n",
        "    # Get the max Q values of states after transition by running next_state through target_q_net and take max Q values for all actions for each sample\n",
        "    next_q = self.target_q_net(next_state_batch).numpy()\n",
        "    max_next_q = np.amax(next_q, axis=1)\n",
        "    print(\"Entering loop\")\n",
        "    print(\"Printing next q\")\n",
        "    print(next_q)\n",
        "    print(\"Printing max next q\")\n",
        "    print(max_next_q)\n",
        "    # Update Q value of action taken with max Q value of next state plus intermediate reward from the action taken\n",
        "    for i in range(state_batch.shape[0]):\n",
        "      target_q_val = reward_batch[i].astype(float)\n",
        "      action_index = action_batch[i]\n",
        "      print(action_index)\n",
        "      if not done_batch[i]:\n",
        "        target_q_val += 0.95 * max_next_q[i]\n",
        "      target_q[i][action_index] = target_q_val\n",
        "    print(\"Finishing loop\")\n",
        "    # Train q_net with target Q values\n",
        "    training_his = self.q_net.fit(x = state_batch, y=target_q)\n",
        "    loss = training_his.history['loss']\n",
        "    print(\"Exiting train\")\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "RkD8jJnfP6wN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_training(env, agent):\n",
        "  '''\n",
        "  Evaluates performance of DQN agent and calculates average reward\n",
        "  PARAM -\n",
        "  env: game environment\n",
        "  agent: DQN agent\n",
        "  RETURNS: Average reward across episodes\n",
        "  '''\n",
        "  total_reward = 0.0\n",
        "  episodes_to_play = 6\n",
        "  for i in range(episodes_to_play):\n",
        "    key = jax.random.PRNGKey(1)\n",
        "    state, timestep = jax.jit(env.reset)(key)\n",
        "    done = False\n",
        "    episode_reward = 0.0\n",
        "    while not done:\n",
        "      action, action_index = agent.policy(state)\n",
        "      if action is False:\n",
        "        done = True\n",
        "        break\n",
        "      next_state, next_timestep = jax.jit(env.step)(state, action)\n",
        "      episode_reward += next_state.reward\n",
        "      state = next_state\n",
        "    total_reward += episode_reward\n",
        "  average_reward = total_reward / episodes_to_play\n",
        "  return average_reward\n",
        "\n",
        "def collect_experiences(env, agent, buffer):\n",
        "  '''\n",
        "  Collect gameplay experiences by playing with env and store experiences in buffer\n",
        "  '''\n",
        "  key = jax.random.PRNGKey(1)\n",
        "  state, timestep = jax.jit(env.reset)(key)\n",
        "  done = False\n",
        "  terminal = False\n",
        "\n",
        "\n",
        "  print(\"Entering Loop\")\n",
        "  while not done:\n",
        "    action, action_index = agent.policy(state)\n",
        "    print(action)\n",
        "    # Testing\n",
        "    #action = agent.random_action(state)\n",
        "    if action is False:\n",
        "      done = True\n",
        "      terminal = True\n",
        "      break\n",
        "    print(state.action_mask)\n",
        "    print(action)\n",
        "    next_state, next_timestep = jax.jit(env.step)(state, action)\n",
        "    print(\"Action taken\")\n",
        "    # env.render(state)\n",
        "    print(action)\n",
        "    buffer.store(agent.convert_state(state), agent.convert_state(next_state), next_state.reward, action_index, terminal)\n",
        "    state = next_state\n",
        "\n",
        "    # sleep(5)\n",
        "\n",
        "    env.render(state)\n",
        "\n",
        "def train_model(max_episodes = 10):\n",
        "  '''\n",
        "  Trains DQN agent to play game\n",
        "  RETURNS: None\n",
        "  '''\n",
        "\n",
        "  agent = DqnAgent()\n",
        "  buffer = ReplayBuffer()\n",
        "  # Instantiate tetris environment using registry\n",
        "  env = jumanji.make('Tetris-v0', num_rows = 5, time_limit = 1000)\n",
        "  # env = jumanji.make('Tetris-v0')\n",
        "\n",
        "\n",
        "  for episode_cnt in range(max_episodes):\n",
        "    collect_experiences(env, agent, buffer)\n",
        "    gameplay_batch = buffer.sample()\n",
        "    loss = agent.train(gameplay_batch)\n",
        "    print('So far the loss is {0}'.format(loss))\n",
        "    avg_reward = evaluate_training(env, agent)\n",
        "    print('So far the performance is {0}'.format(avg_reward))\n",
        "    # Update target q net every __ episodes (currently 2)\n",
        "    if episode_cnt % 2 == 0:\n",
        "      agent.update_network()\n",
        "#    sleep(5)\n"
      ],
      "metadata": {
        "id": "PbeZ_eiJR0dR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model()\n",
        "print('No problems')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yVea72IKNeys",
        "outputId": "8d461f80-edf5-4279-b9ac-330dd94670bc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999.]]\n",
            "[]\n",
            "False\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 5]\n",
            " [0 0 0 ... 0 0 3]\n",
            " ...\n",
            " [0 0 0 ... 0 0 3]\n",
            " [0 0 0 ... 0 0 5]\n",
            " [0 0 0 ... 0 0 6]]\n",
            "[[0 0 0 ... 0 0 5]\n",
            " [8 8 8 ... 0 0 3]\n",
            " [0 0 0 ... 0 0 2]\n",
            " ...\n",
            " [0 0 0 ... 0 0 2]\n",
            " [0 0 0 ... 0 0 2]\n",
            " [0 0 0 ... 0 0 3]]\n",
            "REWARD\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0.]\n",
            "ACTION\n",
            "[ 0 10 16 31 18  0  8  3 18 18 18 31 18 16 16 14 18 31  0 31 12 31  0 12\n",
            " 16 14 12 14 31  0 12 12  0 18 16 24 14  0 30 16 12 14 16 14  3 30 16 16\n",
            " 14 31 18 31 31 16 12 16 16 35 20 10  0 18 16 24 36 16 18 16 35 31 14 18\n",
            " 35  3 16]\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False]\n",
            "Printing current q\n",
            "[[ 5.6658487   1.0259954   1.9299827  ... -2.8016238  -4.18943\n",
            "   3.5486479 ]\n",
            " [ 0.24081033  1.4867269   7.1240377  ... -3.65759    -2.496394\n",
            "   1.6977534 ]\n",
            " [ 0.12586994  0.13824216  0.88442546 ...  0.1427581  -0.5910662\n",
            "   0.4659531 ]\n",
            " ...\n",
            " [ 0.23054907 -0.15001875  0.24475785 ... -0.10900076 -0.24923414\n",
            "   0.42567486]\n",
            " [ 0.8163749  -2.1170108   1.477527   ... -2.3796587  -1.1857748\n",
            "   1.4163692 ]\n",
            " [ 0.12089973  0.12213915  1.3145591  ...  0.09677187 -0.8830356\n",
            "   1.0447228 ]]\n",
            "Printing target q\n",
            "(75, 40)\n",
            "Entering loop\n",
            "Printing next q\n",
            "[[ 6.4926176  -1.6872942   2.986682   ... -4.0963025  -2.3901794\n",
            "   3.8152766 ]\n",
            " [ 6.9944196   0.9035905   8.559042   ... -1.7055465  -6.8256497\n",
            "   2.2973704 ]\n",
            " [ 0.43613687 -0.14149271  0.9937816  ... -0.89142615 -1.1719847\n",
            "   0.15861148]\n",
            " ...\n",
            " [ 0.3468982  -0.8454352   1.1590104  ... -0.9970774  -0.48374525\n",
            "   0.1073823 ]\n",
            " [ 0.21362823 -3.4584782   2.149653   ... -1.1885802  -0.8552167\n",
            "   2.9360318 ]\n",
            " [ 0.12586994  0.13824216  0.88442546 ...  0.1427581  -0.5910662\n",
            "   0.4659531 ]]\n",
            "Printing max next q\n",
            "[11.673338  14.56266    2.66982    4.499281   6.3170333 11.673338\n",
            "  2.937769   2.7247913  7.8563886  6.3170333  6.3170333  4.499281\n",
            " 14.59749    2.66982    1.5676222  8.729052   6.3170333  4.499281\n",
            " 11.673338   8.361463   3.680093   4.499281  11.673338   3.680093\n",
            "  2.66982    8.729052   3.680093   8.729052   4.499281  10.729575\n",
            "  3.680093   3.680093  11.673338   6.3170333  2.66982   11.858128\n",
            "  8.729052  11.673338   1.9098836  1.5676222  3.680093   8.729052\n",
            "  1.5676222  1.1168263  6.5794005  1.9098836  1.5676222  2.66982\n",
            "  8.729052   4.499281   6.3170333  4.497566   4.499281   2.66982\n",
            "  3.680093   4.5752883  2.66982    1.2682645 12.193783  14.56266\n",
            " 11.673338   6.3170333  1.5676222 11.858128   6.8574     1.5676222\n",
            " 14.59749    4.5752883  1.2682645  8.361463   8.729052   7.8563886\n",
            "  1.50983    6.5794005  1.5676222]\n",
            "0\n",
            "10\n",
            "16\n",
            "31\n",
            "18\n",
            "0\n",
            "8\n",
            "3\n",
            "18\n",
            "18\n",
            "18\n",
            "31\n",
            "18\n",
            "16\n",
            "16\n",
            "14\n",
            "18\n",
            "31\n",
            "0\n",
            "31\n",
            "12\n",
            "31\n",
            "0\n",
            "12\n",
            "16\n",
            "14\n",
            "12\n",
            "14\n",
            "31\n",
            "0\n",
            "12\n",
            "12\n",
            "0\n",
            "18\n",
            "16\n",
            "24\n",
            "14\n",
            "0\n",
            "30\n",
            "16\n",
            "12\n",
            "14\n",
            "16\n",
            "14\n",
            "3\n",
            "30\n",
            "16\n",
            "16\n",
            "14\n",
            "31\n",
            "18\n",
            "31\n",
            "31\n",
            "16\n",
            "12\n",
            "16\n",
            "16\n",
            "35\n",
            "20\n",
            "10\n",
            "0\n",
            "18\n",
            "16\n",
            "24\n",
            "36\n",
            "16\n",
            "18\n",
            "16\n",
            "35\n",
            "31\n",
            "14\n",
            "18\n",
            "35\n",
            "3\n",
            "16\n",
            "Finishing loop\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1837\n",
            "Exiting train\n",
            "So far the loss is [0.18367744982242584]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True False False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.4428446e-01  1.5330723e-01  1.3817475e+00  1.2873179e+00\n",
            "  -6.1451614e-01 -1.2433692e-02  4.7591418e-02 -9.7780770e-01\n",
            "   1.0480727e+00 -9.9900000e+02 -1.5956300e-01 -5.7600093e-01\n",
            "   5.2726805e-01 -4.0801832e-01  1.9179840e+00  1.1690556e+00\n",
            "   1.7796141e+00 -7.3608792e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -5.1796138e-01  1.2780269e+00  1.6364555e-01 -2.0590806e+00\n",
            "  -6.1173868e-01 -5.8056772e-01  2.2448553e-01 -1.4396635e-01\n",
            "   6.1451566e-01 -9.9900000e+02  7.2834474e-01  1.3635066e+00\n",
            "  -2.2576997e+00  3.7007704e-01  4.4192722e-01  1.1478636e+00\n",
            "   6.4162153e-01  1.5484062e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 20 21 22 23 24 25 26\n",
            " 27 28 30 31 32 33 34 35 36 37]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.5450844e-01 -1.4148344e-01  2.6257402e-01  9.8119932e-01\n",
            "   2.3812640e-01  3.2568991e-01  1.7045234e-01 -6.7006958e-01\n",
            "   3.8580549e-01 -9.9900000e+02  2.4086192e-01 -3.5255581e-01\n",
            "   4.6586439e-01 -5.8323550e-01  1.0277114e+00  6.7388338e-01\n",
            "   5.6540167e-01 -4.1619658e-01  7.4601495e-01 -9.9900000e+02\n",
            "  -1.5895021e-01  6.0211623e-01 -1.8635871e-01 -1.3665543e+00\n",
            "  -5.6505954e-01 -3.5293353e-01 -2.2599155e-02  9.1881700e-02\n",
            "   1.3237846e-01 -9.9900000e+02  1.7413965e-01  8.2304245e-01\n",
            "  -7.0292896e-01  2.5643189e-02 -5.8597788e-02  1.1068729e+00\n",
            "   5.0254667e-01 -8.4075540e-02 -2.3235714e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25\n",
            " 26 27 28 30 31 32 33 34 35 36 37 38]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True False False  True  True\n",
            "  True  True  True False False  True  True False  True  True  True  True\n",
            "  True  True  True  True False False  True  True  True  True  True False\n",
            " False  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 4.4987357e-01 -8.6327094e-01  1.1958988e+00  1.4708934e+00\n",
            "   5.2613711e-01  7.2628409e-01 -2.3901795e-01 -2.2878824e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  2.4058191e-01 -9.5237100e-01\n",
            "   9.5777953e-01 -1.2630445e+00  1.0978069e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2556179e-01  7.0985764e-01 -9.9900000e+02\n",
            "   4.2103493e-01  9.8763931e-01  2.2683452e-01 -1.4231541e+00\n",
            "   7.0469715e-02 -9.4648749e-01  2.6276520e-01 -4.6657038e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.9958507e-01  1.1918250e+00\n",
            "  -8.1486076e-01  2.7192938e-01  7.1050145e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.8579407e-01 -4.9137613e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7 10 11 12 13 14 17 18 20 21 22 23 24 25 26 27 30\n",
            " 31 32 33 34 37 38]\n",
            "ACTION MASK\n",
            "[ True  True False False False False False  True  True False  True False\n",
            " False False False False  True  True False False  True  True False False\n",
            " False False  True  True  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-5.0449684e-02 -3.7648323e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02  7.0370418e-01\n",
            "   1.8328851e+00 -9.9900000e+02  2.8695278e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1765965e+00 -1.2250943e-01 -9.9900000e+02 -9.9900000e+02\n",
            "   4.1904378e-01  6.5715408e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.1188104e+00 -2.3479390e-01\n",
            "   2.6899752e-01 -9.9900000e+02  3.9539683e-01 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1920190e+00 -1.2723535e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  7  8 10 16 17 20 21 26 27 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False  True  True  True False False  True  True\n",
            " False False False False False  True False False  True False False False\n",
            " False  True  True  True False False  True  True False False False False\n",
            " False  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.3829304e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02  1.3067539e+00 -7.5097576e-02  6.9249499e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.2381517e-01 -1.4035877e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -6.0721010e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.3415434e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2062852e-01  1.2659450e+00 -8.6359572e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3270087e+00  2.4735026e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1720489e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  5  6  7 10 11 17 20 25 26 27 30 31 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False False  True False\n",
            " False False False False  True  True False False  True False False False\n",
            " False False  True False  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.6191460e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  2.0512540e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.2302246e+00 -2.8302231e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -2.3269043e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3663728e+00 -9.9900000e+02\n",
            "   1.7229990e+00 -9.9900000e+02  1.9937761e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.6936903e+00 -6.7253530e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0 10 16 17 20 26 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False  True False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False  True False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.3446233e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1066219e+00 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.8619647e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -8.4938836e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  9 20 29]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.0780706e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[20]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999.]]\n",
            "[]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True False False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.4428446e-01  1.5330723e-01  1.3817475e+00  1.2873179e+00\n",
            "  -6.1451614e-01 -1.2433692e-02  4.7591418e-02 -9.7780770e-01\n",
            "   1.0480727e+00 -9.9900000e+02 -1.5956300e-01 -5.7600093e-01\n",
            "   5.2726805e-01 -4.0801832e-01  1.9179840e+00  1.1690556e+00\n",
            "   1.7796141e+00 -7.3608792e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -5.1796138e-01  1.2780269e+00  1.6364555e-01 -2.0590806e+00\n",
            "  -6.1173868e-01 -5.8056772e-01  2.2448553e-01 -1.4396635e-01\n",
            "   6.1451566e-01 -9.9900000e+02  7.2834474e-01  1.3635066e+00\n",
            "  -2.2576997e+00  3.7007704e-01  4.4192722e-01  1.1478636e+00\n",
            "   6.4162153e-01  1.5484062e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 20 21 22 23 24 25 26\n",
            " 27 28 30 31 32 33 34 35 36 37]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.5450844e-01 -1.4148344e-01  2.6257402e-01  9.8119932e-01\n",
            "   2.3812640e-01  3.2568991e-01  1.7045234e-01 -6.7006958e-01\n",
            "   3.8580549e-01 -9.9900000e+02  2.4086192e-01 -3.5255581e-01\n",
            "   4.6586439e-01 -5.8323550e-01  1.0277114e+00  6.7388338e-01\n",
            "   5.6540167e-01 -4.1619658e-01  7.4601495e-01 -9.9900000e+02\n",
            "  -1.5895021e-01  6.0211623e-01 -1.8635871e-01 -1.3665543e+00\n",
            "  -5.6505954e-01 -3.5293353e-01 -2.2599155e-02  9.1881700e-02\n",
            "   1.3237846e-01 -9.9900000e+02  1.7413965e-01  8.2304245e-01\n",
            "  -7.0292896e-01  2.5643189e-02 -5.8597788e-02  1.1068729e+00\n",
            "   5.0254667e-01 -8.4075540e-02 -2.3235714e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25\n",
            " 26 27 28 30 31 32 33 34 35 36 37 38]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True False False  True  True\n",
            "  True  True  True False False  True  True False  True  True  True  True\n",
            "  True  True  True  True False False  True  True  True  True  True False\n",
            " False  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 4.4987357e-01 -8.6327094e-01  1.1958988e+00  1.4708934e+00\n",
            "   5.2613711e-01  7.2628409e-01 -2.3901795e-01 -2.2878824e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  2.4058191e-01 -9.5237100e-01\n",
            "   9.5777953e-01 -1.2630445e+00  1.0978069e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2556179e-01  7.0985764e-01 -9.9900000e+02\n",
            "   4.2103493e-01  9.8763931e-01  2.2683452e-01 -1.4231541e+00\n",
            "   7.0469715e-02 -9.4648749e-01  2.6276520e-01 -4.6657038e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.9958507e-01  1.1918250e+00\n",
            "  -8.1486076e-01  2.7192938e-01  7.1050145e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.8579407e-01 -4.9137613e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7 10 11 12 13 14 17 18 20 21 22 23 24 25 26 27 30\n",
            " 31 32 33 34 37 38]\n",
            "ACTION MASK\n",
            "[ True  True False False False False False  True  True False  True False\n",
            " False False False False  True  True False False  True  True False False\n",
            " False False  True  True  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-5.0449684e-02 -3.7648323e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02  7.0370418e-01\n",
            "   1.8328851e+00 -9.9900000e+02  2.8695278e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1765965e+00 -1.2250943e-01 -9.9900000e+02 -9.9900000e+02\n",
            "   4.1904378e-01  6.5715408e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.1188104e+00 -2.3479390e-01\n",
            "   2.6899752e-01 -9.9900000e+02  3.9539683e-01 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1920190e+00 -1.2723535e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  7  8 10 16 17 20 21 26 27 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False  True  True  True False False  True  True\n",
            " False False False False False  True False False  True False False False\n",
            " False  True  True  True False False  True  True False False False False\n",
            " False  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.3829304e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02  1.3067539e+00 -7.5097576e-02  6.9249499e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.2381517e-01 -1.4035877e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -6.0721010e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.3415434e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2062852e-01  1.2659450e+00 -8.6359572e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3270087e+00  2.4735026e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1720489e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  5  6  7 10 11 17 20 25 26 27 30 31 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False False  True False\n",
            " False False False False  True  True False False  True False False False\n",
            " False False  True False  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.6191460e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  2.0512540e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.2302246e+00 -2.8302231e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -2.3269043e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3663728e+00 -9.9900000e+02\n",
            "   1.7229990e+00 -9.9900000e+02  1.9937761e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.6936903e+00 -6.7253530e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0 10 16 17 20 26 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False  True False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False  True False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.3446233e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1066219e+00 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.8619647e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -8.4938836e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  9 20 29]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.0780706e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[20]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999.]]\n",
            "[]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True False False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.4428446e-01  1.5330723e-01  1.3817475e+00  1.2873179e+00\n",
            "  -6.1451614e-01 -1.2433692e-02  4.7591418e-02 -9.7780770e-01\n",
            "   1.0480727e+00 -9.9900000e+02 -1.5956300e-01 -5.7600093e-01\n",
            "   5.2726805e-01 -4.0801832e-01  1.9179840e+00  1.1690556e+00\n",
            "   1.7796141e+00 -7.3608792e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -5.1796138e-01  1.2780269e+00  1.6364555e-01 -2.0590806e+00\n",
            "  -6.1173868e-01 -5.8056772e-01  2.2448553e-01 -1.4396635e-01\n",
            "   6.1451566e-01 -9.9900000e+02  7.2834474e-01  1.3635066e+00\n",
            "  -2.2576997e+00  3.7007704e-01  4.4192722e-01  1.1478636e+00\n",
            "   6.4162153e-01  1.5484062e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 20 21 22 23 24 25 26\n",
            " 27 28 30 31 32 33 34 35 36 37]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.5450844e-01 -1.4148344e-01  2.6257402e-01  9.8119932e-01\n",
            "   2.3812640e-01  3.2568991e-01  1.7045234e-01 -6.7006958e-01\n",
            "   3.8580549e-01 -9.9900000e+02  2.4086192e-01 -3.5255581e-01\n",
            "   4.6586439e-01 -5.8323550e-01  1.0277114e+00  6.7388338e-01\n",
            "   5.6540167e-01 -4.1619658e-01  7.4601495e-01 -9.9900000e+02\n",
            "  -1.5895021e-01  6.0211623e-01 -1.8635871e-01 -1.3665543e+00\n",
            "  -5.6505954e-01 -3.5293353e-01 -2.2599155e-02  9.1881700e-02\n",
            "   1.3237846e-01 -9.9900000e+02  1.7413965e-01  8.2304245e-01\n",
            "  -7.0292896e-01  2.5643189e-02 -5.8597788e-02  1.1068729e+00\n",
            "   5.0254667e-01 -8.4075540e-02 -2.3235714e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25\n",
            " 26 27 28 30 31 32 33 34 35 36 37 38]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True False False  True  True\n",
            "  True  True  True False False  True  True False  True  True  True  True\n",
            "  True  True  True  True False False  True  True  True  True  True False\n",
            " False  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 4.4987357e-01 -8.6327094e-01  1.1958988e+00  1.4708934e+00\n",
            "   5.2613711e-01  7.2628409e-01 -2.3901795e-01 -2.2878824e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  2.4058191e-01 -9.5237100e-01\n",
            "   9.5777953e-01 -1.2630445e+00  1.0978069e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2556179e-01  7.0985764e-01 -9.9900000e+02\n",
            "   4.2103493e-01  9.8763931e-01  2.2683452e-01 -1.4231541e+00\n",
            "   7.0469715e-02 -9.4648749e-01  2.6276520e-01 -4.6657038e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.9958507e-01  1.1918250e+00\n",
            "  -8.1486076e-01  2.7192938e-01  7.1050145e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.8579407e-01 -4.9137613e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7 10 11 12 13 14 17 18 20 21 22 23 24 25 26 27 30\n",
            " 31 32 33 34 37 38]\n",
            "ACTION MASK\n",
            "[ True  True False False False False False  True  True False  True False\n",
            " False False False False  True  True False False  True  True False False\n",
            " False False  True  True  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-5.0449684e-02 -3.7648323e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02  7.0370418e-01\n",
            "   1.8328851e+00 -9.9900000e+02  2.8695278e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1765965e+00 -1.2250943e-01 -9.9900000e+02 -9.9900000e+02\n",
            "   4.1904378e-01  6.5715408e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.1188104e+00 -2.3479390e-01\n",
            "   2.6899752e-01 -9.9900000e+02  3.9539683e-01 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1920190e+00 -1.2723535e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  7  8 10 16 17 20 21 26 27 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False  True  True  True False False  True  True\n",
            " False False False False False  True False False  True False False False\n",
            " False  True  True  True False False  True  True False False False False\n",
            " False  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.3829304e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02  1.3067539e+00 -7.5097576e-02  6.9249499e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.2381517e-01 -1.4035877e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -6.0721010e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.3415434e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2062852e-01  1.2659450e+00 -8.6359572e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3270087e+00  2.4735026e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1720489e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  5  6  7 10 11 17 20 25 26 27 30 31 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False False  True False\n",
            " False False False False  True  True False False  True False False False\n",
            " False False  True False  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.6191460e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  2.0512540e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.2302246e+00 -2.8302231e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -2.3269043e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3663728e+00 -9.9900000e+02\n",
            "   1.7229990e+00 -9.9900000e+02  1.9937761e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.6936903e+00 -6.7253530e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0 10 16 17 20 26 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False  True False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False  True False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.3446233e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1066219e+00 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.8619647e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -8.4938836e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  9 20 29]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.0780706e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[20]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999.]]\n",
            "[]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True False False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.4428446e-01  1.5330723e-01  1.3817475e+00  1.2873179e+00\n",
            "  -6.1451614e-01 -1.2433692e-02  4.7591418e-02 -9.7780770e-01\n",
            "   1.0480727e+00 -9.9900000e+02 -1.5956300e-01 -5.7600093e-01\n",
            "   5.2726805e-01 -4.0801832e-01  1.9179840e+00  1.1690556e+00\n",
            "   1.7796141e+00 -7.3608792e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -5.1796138e-01  1.2780269e+00  1.6364555e-01 -2.0590806e+00\n",
            "  -6.1173868e-01 -5.8056772e-01  2.2448553e-01 -1.4396635e-01\n",
            "   6.1451566e-01 -9.9900000e+02  7.2834474e-01  1.3635066e+00\n",
            "  -2.2576997e+00  3.7007704e-01  4.4192722e-01  1.1478636e+00\n",
            "   6.4162153e-01  1.5484062e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 20 21 22 23 24 25 26\n",
            " 27 28 30 31 32 33 34 35 36 37]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.5450844e-01 -1.4148344e-01  2.6257402e-01  9.8119932e-01\n",
            "   2.3812640e-01  3.2568991e-01  1.7045234e-01 -6.7006958e-01\n",
            "   3.8580549e-01 -9.9900000e+02  2.4086192e-01 -3.5255581e-01\n",
            "   4.6586439e-01 -5.8323550e-01  1.0277114e+00  6.7388338e-01\n",
            "   5.6540167e-01 -4.1619658e-01  7.4601495e-01 -9.9900000e+02\n",
            "  -1.5895021e-01  6.0211623e-01 -1.8635871e-01 -1.3665543e+00\n",
            "  -5.6505954e-01 -3.5293353e-01 -2.2599155e-02  9.1881700e-02\n",
            "   1.3237846e-01 -9.9900000e+02  1.7413965e-01  8.2304245e-01\n",
            "  -7.0292896e-01  2.5643189e-02 -5.8597788e-02  1.1068729e+00\n",
            "   5.0254667e-01 -8.4075540e-02 -2.3235714e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25\n",
            " 26 27 28 30 31 32 33 34 35 36 37 38]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True False False  True  True\n",
            "  True  True  True False False  True  True False  True  True  True  True\n",
            "  True  True  True  True False False  True  True  True  True  True False\n",
            " False  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 4.4987357e-01 -8.6327094e-01  1.1958988e+00  1.4708934e+00\n",
            "   5.2613711e-01  7.2628409e-01 -2.3901795e-01 -2.2878824e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  2.4058191e-01 -9.5237100e-01\n",
            "   9.5777953e-01 -1.2630445e+00  1.0978069e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2556179e-01  7.0985764e-01 -9.9900000e+02\n",
            "   4.2103493e-01  9.8763931e-01  2.2683452e-01 -1.4231541e+00\n",
            "   7.0469715e-02 -9.4648749e-01  2.6276520e-01 -4.6657038e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.9958507e-01  1.1918250e+00\n",
            "  -8.1486076e-01  2.7192938e-01  7.1050145e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.8579407e-01 -4.9137613e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7 10 11 12 13 14 17 18 20 21 22 23 24 25 26 27 30\n",
            " 31 32 33 34 37 38]\n",
            "ACTION MASK\n",
            "[ True  True False False False False False  True  True False  True False\n",
            " False False False False  True  True False False  True  True False False\n",
            " False False  True  True  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-5.0449684e-02 -3.7648323e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02  7.0370418e-01\n",
            "   1.8328851e+00 -9.9900000e+02  2.8695278e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1765965e+00 -1.2250943e-01 -9.9900000e+02 -9.9900000e+02\n",
            "   4.1904378e-01  6.5715408e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.1188104e+00 -2.3479390e-01\n",
            "   2.6899752e-01 -9.9900000e+02  3.9539683e-01 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1920190e+00 -1.2723535e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  7  8 10 16 17 20 21 26 27 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False  True  True  True False False  True  True\n",
            " False False False False False  True False False  True False False False\n",
            " False  True  True  True False False  True  True False False False False\n",
            " False  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.3829304e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02  1.3067539e+00 -7.5097576e-02  6.9249499e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.2381517e-01 -1.4035877e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -6.0721010e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.3415434e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2062852e-01  1.2659450e+00 -8.6359572e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3270087e+00  2.4735026e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1720489e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  5  6  7 10 11 17 20 25 26 27 30 31 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False False  True False\n",
            " False False False False  True  True False False  True False False False\n",
            " False False  True False  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.6191460e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  2.0512540e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.2302246e+00 -2.8302231e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -2.3269043e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3663728e+00 -9.9900000e+02\n",
            "   1.7229990e+00 -9.9900000e+02  1.9937761e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.6936903e+00 -6.7253530e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0 10 16 17 20 26 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False  True False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False  True False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.3446233e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1066219e+00 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.8619647e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -8.4938836e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  9 20 29]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.0780706e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[20]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999.]]\n",
            "[]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True False False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.4428446e-01  1.5330723e-01  1.3817475e+00  1.2873179e+00\n",
            "  -6.1451614e-01 -1.2433692e-02  4.7591418e-02 -9.7780770e-01\n",
            "   1.0480727e+00 -9.9900000e+02 -1.5956300e-01 -5.7600093e-01\n",
            "   5.2726805e-01 -4.0801832e-01  1.9179840e+00  1.1690556e+00\n",
            "   1.7796141e+00 -7.3608792e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -5.1796138e-01  1.2780269e+00  1.6364555e-01 -2.0590806e+00\n",
            "  -6.1173868e-01 -5.8056772e-01  2.2448553e-01 -1.4396635e-01\n",
            "   6.1451566e-01 -9.9900000e+02  7.2834474e-01  1.3635066e+00\n",
            "  -2.2576997e+00  3.7007704e-01  4.4192722e-01  1.1478636e+00\n",
            "   6.4162153e-01  1.5484062e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 20 21 22 23 24 25 26\n",
            " 27 28 30 31 32 33 34 35 36 37]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.5450844e-01 -1.4148344e-01  2.6257402e-01  9.8119932e-01\n",
            "   2.3812640e-01  3.2568991e-01  1.7045234e-01 -6.7006958e-01\n",
            "   3.8580549e-01 -9.9900000e+02  2.4086192e-01 -3.5255581e-01\n",
            "   4.6586439e-01 -5.8323550e-01  1.0277114e+00  6.7388338e-01\n",
            "   5.6540167e-01 -4.1619658e-01  7.4601495e-01 -9.9900000e+02\n",
            "  -1.5895021e-01  6.0211623e-01 -1.8635871e-01 -1.3665543e+00\n",
            "  -5.6505954e-01 -3.5293353e-01 -2.2599155e-02  9.1881700e-02\n",
            "   1.3237846e-01 -9.9900000e+02  1.7413965e-01  8.2304245e-01\n",
            "  -7.0292896e-01  2.5643189e-02 -5.8597788e-02  1.1068729e+00\n",
            "   5.0254667e-01 -8.4075540e-02 -2.3235714e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25\n",
            " 26 27 28 30 31 32 33 34 35 36 37 38]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True False False  True  True\n",
            "  True  True  True False False  True  True False  True  True  True  True\n",
            "  True  True  True  True False False  True  True  True  True  True False\n",
            " False  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 4.4987357e-01 -8.6327094e-01  1.1958988e+00  1.4708934e+00\n",
            "   5.2613711e-01  7.2628409e-01 -2.3901795e-01 -2.2878824e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  2.4058191e-01 -9.5237100e-01\n",
            "   9.5777953e-01 -1.2630445e+00  1.0978069e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2556179e-01  7.0985764e-01 -9.9900000e+02\n",
            "   4.2103493e-01  9.8763931e-01  2.2683452e-01 -1.4231541e+00\n",
            "   7.0469715e-02 -9.4648749e-01  2.6276520e-01 -4.6657038e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.9958507e-01  1.1918250e+00\n",
            "  -8.1486076e-01  2.7192938e-01  7.1050145e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.8579407e-01 -4.9137613e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7 10 11 12 13 14 17 18 20 21 22 23 24 25 26 27 30\n",
            " 31 32 33 34 37 38]\n",
            "ACTION MASK\n",
            "[ True  True False False False False False  True  True False  True False\n",
            " False False False False  True  True False False  True  True False False\n",
            " False False  True  True  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-5.0449684e-02 -3.7648323e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02  7.0370418e-01\n",
            "   1.8328851e+00 -9.9900000e+02  2.8695278e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1765965e+00 -1.2250943e-01 -9.9900000e+02 -9.9900000e+02\n",
            "   4.1904378e-01  6.5715408e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.1188104e+00 -2.3479390e-01\n",
            "   2.6899752e-01 -9.9900000e+02  3.9539683e-01 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1920190e+00 -1.2723535e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  7  8 10 16 17 20 21 26 27 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False  True  True  True False False  True  True\n",
            " False False False False False  True False False  True False False False\n",
            " False  True  True  True False False  True  True False False False False\n",
            " False  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.3829304e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02  1.3067539e+00 -7.5097576e-02  6.9249499e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.2381517e-01 -1.4035877e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -6.0721010e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.3415434e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2062852e-01  1.2659450e+00 -8.6359572e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3270087e+00  2.4735026e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1720489e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  5  6  7 10 11 17 20 25 26 27 30 31 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False False  True False\n",
            " False False False False  True  True False False  True False False False\n",
            " False False  True False  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.6191460e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  2.0512540e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.2302246e+00 -2.8302231e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -2.3269043e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3663728e+00 -9.9900000e+02\n",
            "   1.7229990e+00 -9.9900000e+02  1.9937761e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.6936903e+00 -6.7253530e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0 10 16 17 20 26 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False  True False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False  True False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.3446233e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1066219e+00 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.8619647e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -8.4938836e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  9 20 29]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.0780706e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[20]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999.]]\n",
            "[]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True False False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.4428446e-01  1.5330723e-01  1.3817475e+00  1.2873179e+00\n",
            "  -6.1451614e-01 -1.2433692e-02  4.7591418e-02 -9.7780770e-01\n",
            "   1.0480727e+00 -9.9900000e+02 -1.5956300e-01 -5.7600093e-01\n",
            "   5.2726805e-01 -4.0801832e-01  1.9179840e+00  1.1690556e+00\n",
            "   1.7796141e+00 -7.3608792e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -5.1796138e-01  1.2780269e+00  1.6364555e-01 -2.0590806e+00\n",
            "  -6.1173868e-01 -5.8056772e-01  2.2448553e-01 -1.4396635e-01\n",
            "   6.1451566e-01 -9.9900000e+02  7.2834474e-01  1.3635066e+00\n",
            "  -2.2576997e+00  3.7007704e-01  4.4192722e-01  1.1478636e+00\n",
            "   6.4162153e-01  1.5484062e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 20 21 22 23 24 25 26\n",
            " 27 28 30 31 32 33 34 35 36 37]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True False  True  True  True  True\n",
            "  True  True  True  True  True False  True  True  True  True  True  True\n",
            "  True  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.5450844e-01 -1.4148344e-01  2.6257402e-01  9.8119932e-01\n",
            "   2.3812640e-01  3.2568991e-01  1.7045234e-01 -6.7006958e-01\n",
            "   3.8580549e-01 -9.9900000e+02  2.4086192e-01 -3.5255581e-01\n",
            "   4.6586439e-01 -5.8323550e-01  1.0277114e+00  6.7388338e-01\n",
            "   5.6540167e-01 -4.1619658e-01  7.4601495e-01 -9.9900000e+02\n",
            "  -1.5895021e-01  6.0211623e-01 -1.8635871e-01 -1.3665543e+00\n",
            "  -5.6505954e-01 -3.5293353e-01 -2.2599155e-02  9.1881700e-02\n",
            "   1.3237846e-01 -9.9900000e+02  1.7413965e-01  8.2304245e-01\n",
            "  -7.0292896e-01  2.5643189e-02 -5.8597788e-02  1.1068729e+00\n",
            "   5.0254667e-01 -8.4075540e-02 -2.3235714e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15 16 17 18 20 21 22 23 24 25\n",
            " 26 27 28 30 31 32 33 34 35 36 37 38]\n",
            "ACTION MASK\n",
            "[ True  True  True  True  True  True  True  True False False  True  True\n",
            "  True  True  True False False  True  True False  True  True  True  True\n",
            "  True  True  True  True False False  True  True  True  True  True False\n",
            " False  True  True False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 4.4987357e-01 -8.6327094e-01  1.1958988e+00  1.4708934e+00\n",
            "   5.2613711e-01  7.2628409e-01 -2.3901795e-01 -2.2878824e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  2.4058191e-01 -9.5237100e-01\n",
            "   9.5777953e-01 -1.2630445e+00  1.0978069e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2556179e-01  7.0985764e-01 -9.9900000e+02\n",
            "   4.2103493e-01  9.8763931e-01  2.2683452e-01 -1.4231541e+00\n",
            "   7.0469715e-02 -9.4648749e-01  2.6276520e-01 -4.6657038e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.9958507e-01  1.1918250e+00\n",
            "  -8.1486076e-01  2.7192938e-01  7.1050145e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.8579407e-01 -4.9137613e-01 -9.9900000e+02]]\n",
            "[ 0  1  2  3  4  5  6  7 10 11 12 13 14 17 18 20 21 22 23 24 25 26 27 30\n",
            " 31 32 33 34 37 38]\n",
            "ACTION MASK\n",
            "[ True  True False False False False False  True  True False  True False\n",
            " False False False False  True  True False False  True  True False False\n",
            " False False  True  True  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-5.0449684e-02 -3.7648323e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02  7.0370418e-01\n",
            "   1.8328851e+00 -9.9900000e+02  2.8695278e-02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1765965e+00 -1.2250943e-01 -9.9900000e+02 -9.9900000e+02\n",
            "   4.1904378e-01  6.5715408e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.1188104e+00 -2.3479390e-01\n",
            "   2.6899752e-01 -9.9900000e+02  3.9539683e-01 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.1920190e+00 -1.2723535e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  1  7  8 10 16 17 20 21 26 27 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False  True  True  True False False  True  True\n",
            " False False False False False  True False False  True False False False\n",
            " False  True  True  True False False  True  True False False False False\n",
            " False  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.3829304e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02  1.3067539e+00 -7.5097576e-02  6.9249499e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  8.2381517e-01 -1.4035877e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -6.0721010e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.3415434e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -3.2062852e-01  1.2659450e+00 -8.6359572e-01\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3270087e+00  2.4735026e+00\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1720489e+00 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  5  6  7 10 11 17 20 25 26 27 30 31 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False False  True False\n",
            " False False False False  True  True False False  True False False False\n",
            " False False  True False  True False  True False False False False False\n",
            "  True  True False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 1.6191460e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  2.0512540e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   1.2302246e+00 -2.8302231e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -2.3269043e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02  1.3663728e+00 -9.9900000e+02\n",
            "   1.7229990e+00 -9.9900000e+02  1.9937761e+00 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.6936903e+00 -6.7253530e-01 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0 10 16 17 20 26 28 30 36 37]\n",
            "ACTION MASK\n",
            "[ True False False False False False False False False  True False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False  True False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[ 2.3446233e+00 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -1.1066219e+00 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -7.8619647e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -8.4938836e-01 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[ 0  9 20 29]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "   2.0780706e-01 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02\n",
            "  -9.9900000e+02 -9.9900000e+02 -9.9900000e+02 -9.9900000e+02]]\n",
            "[20]\n",
            "ACTION MASK\n",
            "[False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False]\n",
            "CORRESPONDING Q VALUES\n",
            "[[-999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999. -999.\n",
            "  -999. -999. -999. -999.]]\n",
            "[]\n",
            "So far the performance is 0.0\n",
            "No problems\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "n0FrByr_QNZG"
      }
    }
  ]
}